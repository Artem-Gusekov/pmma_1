{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import seaborn as sns\n",
    "import rampy as rp\n",
    "import math\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import lmfit\n",
    "\n",
    "from BaselineRemoval import BaselineRemoval\n",
    "from pybaselines import Baseline, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import transforms\n",
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a939b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', center_color='k', text=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of `x` and `y`\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like, shape (n, )\n",
    "        Input data.\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "\n",
    "    ax.plot(mean_x, mean_y, marker='+', color='w', ms=12, mew=4)\n",
    "    ax.plot(mean_x, mean_y, marker='+', color=center_color, ms=12, mew=1.5)\n",
    "\n",
    "    # if text is not None:\n",
    "    #     ax.annotate(\n",
    "    #         text,\n",
    "    #         (mean_x, mean_y),\n",
    "    #         xytext=(-5, 5),\n",
    "    #         textcoords='offset points',\n",
    "    #         fontsize=20,\n",
    "    #         ha='left',\n",
    "    #         va='bottom', color='w'\n",
    "    #     )\n",
    "\n",
    "    if text is not None:\n",
    "        txt = ax.annotate(\n",
    "            text,\n",
    "            (mean_x, mean_y),\n",
    "            xytext=(-5, 5),\n",
    "            textcoords='offset points',\n",
    "            fontsize=20,\n",
    "            color='k',\n",
    "            ha='left',\n",
    "            va='bottom',\n",
    "            bbox=dict(\n",
    "        boxstyle='round,pad=0.1',\n",
    "        facecolor='white',\n",
    "        edgecolor='none',\n",
    "        alpha=0.6\n",
    "    )\n",
    "        )\n",
    "        txt.set_path_effects([\n",
    "            pe.withStroke(linewidth=1, foreground='white')\n",
    "        ])\n",
    "\n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_spectra_by_peak(x, df, reference_peak=812, window=10):\n",
    "    \"\"\"\n",
    "    Корректирует смещение спектров по эталонному пику.\n",
    "    \n",
    "    df : pd.DataFrame\n",
    "        index = wavenumbers (ось X),\n",
    "        columns = спектры (каждый столбец = отдельный спектр)\n",
    "    reference_peak : float\n",
    "        Ожидаемое положение эталонного пика (например, 812 см⁻¹)\n",
    "    window : float\n",
    "        Допустимое отклонение для поиска максимума (+- window)\n",
    "        \n",
    "    Возвращает скорректированный DataFrame.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    corrected = pd.DataFrame(index=x)\n",
    "\n",
    "    # Определяем диапазон для поиска\n",
    "    mask = (x >= reference_peak - window) & (x <= reference_peak + window)\n",
    "\n",
    "    for col in df.columns:\n",
    "        y = df[col].to_numpy()\n",
    "\n",
    "        # Находим положение локального максимума в окне\n",
    "        local_x = x[mask]\n",
    "        local_y = y[mask]\n",
    "        max_idx = np.argmax(local_y)\n",
    "        peak_pos = local_x[max_idx]\n",
    "\n",
    "        # Сдвиг (сколько нужно сместить, чтобы пик оказался в reference_peak)\n",
    "        shift = int((peak_pos - reference_peak) / 0.5)\n",
    "\n",
    "        if shift == 0:\n",
    "            corrected[col] = y\n",
    "        else:\n",
    "            y_shifted = np.zeros_like(y)\n",
    "            if shift > 0:  # спектр \"правее\" — сдвигаем влево\n",
    "                y_shifted[:-shift] = y[shift:]\n",
    "            else:          # спектр \"левее\" — сдвигаем вправо\n",
    "                y_shifted[-shift:] = y[:shift]\n",
    "            corrected[col] = y_shifted\n",
    "\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e93954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_func(x, df_y, reference_peak=812, window=10):\n",
    "    x = np.asarray(x)\n",
    "    mask = (x >= reference_peak - window) & (x <= reference_peak + window)\n",
    "\n",
    "    y_shifted = pd.DataFrame()\n",
    "    for i in range(df_y.shape[1]):\n",
    "        y = df_y.iloc[:, i].copy()\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        local_x = x[mask]\n",
    "        local_y = y[mask]\n",
    "        max_idx = np.argmax(local_y)\n",
    "        peak_pos = local_x[max_idx]\n",
    "        # peaks_1, _ = find_peaks(y_1, height=0.95, distance=10)\n",
    "\n",
    "        # if peaks_1[-1] != 192:\n",
    "        #     if peaks_1[-1]-192 > 0:\n",
    "        #         sh = peaks_1[-1] - 192\n",
    "        #         len = IR_sm.iloc[sh:, i].shape[0]\n",
    "        #         sh_d = pd.concat((IR_sm.iloc[sh:, i], pd.Series(np.zeros(sh))), axis=0, ignore_index=True)\n",
    "        #         y_shift[i] = sh_d\n",
    "        #     else:\n",
    "        #         sh = abs(peaks_1[-1] - 192)\n",
    "        #         sh_d = pd.concat((pd.Series(np.zeros(sh)), IR_sm.iloc[:, i]), axis=0, ignore_index=True)\n",
    "        #         y_shift[i] = sh_d.iloc[:]\n",
    "        # else:\n",
    "        #     y_shift[i] = IR_sm.iloc[:, i]\n",
    "\n",
    "\n",
    "    return y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_by_one(df_x, df_y, names):\n",
    "    for i in range(df_y.shape[1]):\n",
    "        (pd.concat((pd.Series(df_x),  df_y.iloc[:, i]), axis=1)).to_csv(fr'C:\\Users\\gusen\\Downloads\\аспер\\6 сем\\data\\1\\{names[i]}.dat', sep='\\t', index=None, header=None )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c989ccc",
   "metadata": {},
   "source": [
    "все измерения рамана былы сделаны на 25 мВт \n",
    "\n",
    ".+ в толще на этой же мощности все плавилось "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#ff0000', '#ff8c00', '#ffd700', '#adff2f', '#1e90ff', '#0000cd', \"#7104ff\",\n",
    "          '#00ff7f', '#f08080',  '#ff00ff',  '#dda0dd', '#87ceeb', '#7fffd4', '#ffe4b5',\n",
    "          '#696969', '#2e8b57', '#8b0000', '#808000', '#663399',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ec14f",
   "metadata": {},
   "source": [
    "# Ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma'\n",
    "fold_name_s = re.search(r'[^\\\\/]+$', root_folder)\n",
    "fold_name = fold_name_s.group(0)\n",
    "\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "classes = []\n",
    "classes_n = []\n",
    "samle_names = []\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "\n",
    "for subfolder in sorted(os.listdir(root_folder), key=numericalSort):\n",
    "        subfolder_path = os.path.join(root_folder, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        for file in sorted(os.listdir(subfolder_path), key=numericalSort):\n",
    "            file_path = os.path.join(subfolder_path, file)\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "\n",
    "            # df = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "            df = pd.DataFrame()\n",
    "            if f\"{fold_name}_{subfolder}\" not in classes:\n",
    "                 classes.append(f\"{fold_name}_{subfolder}\")\n",
    "            classes_n.append(f\"{fold_name}_{subfolder}\")\n",
    "            samle_names.append(f\"{fold_name}_{subfolder}_{os.path.splitext(file)[0]}\")\n",
    "            column_name = f\"{fold_name}_{subfolder}_{os.path.splitext(file)[0]}\"\n",
    "            df[column_name] = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "\n",
    "            all_dfs.append(df)\n",
    "\n",
    "if all_dfs:\n",
    "    result = pd.concat(all_dfs, axis=1)\n",
    "else:\n",
    "    result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(samle_names)\n",
    "label_to_num = {label: i for i, label in enumerate(unique_labels)}\n",
    "y = np.array([label_to_num[label] for label in samle_names])\n",
    "\n",
    "colors_n = {}\n",
    "for en,i in enumerate(classes):\n",
    "    colors_n[i] = colors[en]\n",
    "\n",
    "colors_for_points = [colors_n[label] for label in classes_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 0]\n",
    "df_y = result.copy()\n",
    "\n",
    "df_x_copy = df_x.copy()\n",
    "df_y_copy = df_y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817da90",
   "metadata": {},
   "source": [
    "## ram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8114f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_begin = 300\n",
    "x_end = 2000\n",
    "\n",
    "x_begin = df_x_copy[df_x_copy>=x_begin].index[0]\n",
    "x_end = df_x_copy[df_x_copy>=x_end].index[0]\n",
    "\n",
    "df_x = df_x_copy.iloc[x_begin:x_end+1].copy()\n",
    "df_y = df_y_copy.iloc[x_begin:x_end+1, :].copy()\n",
    "\n",
    "df_x.reset_index(drop=True, inplace=True)\n",
    "df_y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_norm = df_y.copy()\n",
    "# for i in range(df_norm.shape[1]):\n",
    "#     df_norm.iloc[:, i] = (df_norm.iloc[:, i] - df_norm.iloc[:, i].mean()) / df_norm.iloc[:, i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = pd.DataFrame(columns=['class', 'name'] + list(df_x))\n",
    "# datas['class'] = classes_mw\n",
    "# datas['name'] = samle_names\n",
    "# datas.iloc[:, 2:] = df_y.T.reset_index(drop=True)\n",
    "# datas.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma_init.csv', index=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "df_bg = pd.DataFrame()\n",
    "df_f = pd.DataFrame()\n",
    "for i in range(df_y.shape[1]):\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.swima(df_y.iloc[:, i],  min_half_window=60, smooth_half_window=10)[0]\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.asls(df_y.iloc[:, i], lam=1e1, p=0.0001)[0]\n",
    "\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.pspline_arpls(df_y.iloc[:, i], lam=1e3, num_knots=2, diff_order=2, max_iter=50)[0]\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.arpls(df_y.iloc[:, i], lam=1e10, diff_order=2, max_iter=500)[0]\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.drpls(df_y.iloc[:, i], lam=1e12, eta=0.1, diff_order=2, max_iter=50)[0]\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.airpls(df_y.iloc[:, i], lam=1e6, max_iter=50, tol=1e-3)[0]\n",
    "\n",
    "    df_bg[samle_names[i]] = baseline_fitter.rubberband(df_y.iloc[:, i], smooth_half_window=25)[0]\n",
    "    df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    # df_bg[samle_names[i]] = concave_rubberband_baseline(df_x, df_y.iloc[:, i])\n",
    "    # df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "#     raman_19sp_f.iloc[:, i] = raman_19sp_f.iloc[:, i] / max(raman_19sp_f.iloc[1400:1650, i])\n",
    "df_f[df_f<0] = 0\n",
    "\n",
    "for i in range(df_f.shape[1]):\n",
    "    # df_smooth[df_names[i]] = savgol_filter(df_y.iloc[:, i], 25, 4)\n",
    "    df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "for i in range(df_f.shape[1]):\n",
    "    df_f.iloc[:, i] = df_f.iloc[:, i] / max(df_f.iloc[:, i])\n",
    "\n",
    "plt.plot(df_x, df_f.iloc[:, :])\n",
    "# plt.xlim((800, 820))\n",
    "# plt.ylim((0.9, 1.1))\n",
    "# plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "# plt.ylabel('$a.u.$')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = r'C:\\Users\\gusen\\Downloads\\аспер\\6 сем\\data\\4'\n",
    "# fold_name_s = re.search(r'[^\\\\/]+$', root_folder)\n",
    "# fold_name = fold_name_s.group(0)\n",
    "\n",
    "# numbers = re.compile(r'(\\d+)')\n",
    "# def numericalSort(value):\n",
    "#     parts = numbers.split(value)\n",
    "#     parts[1::2] = map(int, parts[1::2])\n",
    "#     return parts\n",
    "\n",
    "# all_dfs = []\n",
    "\n",
    "# for file in sorted(os.listdir(cc), key=numericalSort):\n",
    "#     file_path = os.path.join(cc, file)\n",
    "#     if not os.path.isfile(file_path):\n",
    "#         continue\n",
    "#     df = pd.DataFrame()\n",
    "#     df[file[:-4]] = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "\n",
    "#     all_dfs.append(df)\n",
    "\n",
    "# if all_dfs:\n",
    "#     result = pd.concat(all_dfs, axis=1)\n",
    "\n",
    "# df_f = result.copy()\n",
    "# plt.plot(df_x, df_f.iloc[:, :])\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_peak = 812\n",
    "\n",
    "if ref_peak in df_x.values:\n",
    "    df_f = align_spectra_by_peak(df_x, df_f, reference_peak=ref_peak, window=10)\n",
    "\n",
    "    plt.plot(df_x, df_f.iloc[:, :])\n",
    "    plt.xlim((810, 814))\n",
    "    plt.ylim((0.975, 1.025))\n",
    "    # plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "    # plt.ylabel('$a.u.$')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c65099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smooth = pd.DataFrame()\n",
    "\n",
    "for i in range(df_y.shape[1]):\n",
    "    # df_smooth[df_names[i]] = savgol_filter(df_y.iloc[:, i], 25, 4)\n",
    "    df_smooth[samle_names[i]] = gaussian_filter1d(df_f.iloc[:, i], 2)\n",
    "\n",
    "plt.plot(df_x, df_smooth.iloc[:, :])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94819080",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d63f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame()\n",
    "\n",
    "norm_var = 'range'\n",
    "# norm_var = 'snv' \n",
    "\n",
    "peak_window = (1100, 1143)\n",
    "# peak_window = (750, 900)\n",
    "xy = np.asarray(df_x)\n",
    "x_min, x_max = peak_window\n",
    "mask = (xy >= x_min) & (xy <= x_max)\n",
    "\n",
    "if norm_var == 'range':\n",
    "    if len(df_x[mask]) == 0:\n",
    "        for i in range(df_smooth.shape[1]):\n",
    "            df_norm[samle_names[i]] = df_smooth.iloc[:, i] / max(df_smooth.iloc[:, i])\n",
    "    else:\n",
    "        for i in range(df_smooth.shape[1]):\n",
    "            # df_norm[samle_names[i]] = df_smooth.iloc[:, i] / max(df_smooth.iloc[:, i])\n",
    "            df_norm[samle_names[i]] = df_smooth.iloc[:, i] / max(df_smooth.iloc[mask, i])\n",
    "elif norm_var == 'snv':\n",
    "    for i in range(df_smooth.shape[1]):\n",
    "        df_norm[samle_names[i]] = (df_smooth.iloc[:, i] - df_smooth.iloc[:, i].mean()) / df_smooth.iloc[:, i].std()\n",
    "\n",
    "plt.plot(df_x, df_norm.iloc[:, :])\n",
    "\n",
    "# plt.xlim((800, 2000))\n",
    "plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "plt.ylabel('$a.u.$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f237e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''этот мини скрипт может менять количество точек в спектре'''\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "df_y_mod = pd.DataFrame()\n",
    "\n",
    "for i in range(df_norm.shape[1]):\n",
    "    y =  df_norm.iloc[:, i]\n",
    "    x = df_x\n",
    "    f_interp = interp1d(x, y, kind='cubic')\n",
    "    new_x = np.linspace(x.iloc[0], x.iloc[-1], 501)\n",
    "    new_y = f_interp(new_x)\n",
    "    df_y_mod[df_norm.columns[i]] = new_y\n",
    "\n",
    "df_x = new_x.copy()\n",
    "df_norm = df_y_mod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_norm_2 = df_norm.copy()\n",
    "# corrs = pd.DataFrame(columns=df_x, index=(0,1))\n",
    "# for j in range(df_norm_2.shape[0]):\n",
    "#     for i in range(df_norm_2.shape[0]):\n",
    "#         df_norm_2.iloc[i, :] = df_norm_2.iloc[i, :] / df_norm_2.iloc[i, :].max()\n",
    "#     df_norm_2.loc[len(df_norm_2), :] = classes_mw\n",
    "#     j_corr = df_norm_2.T.corr()\n",
    "#     corrs[df_x[j]] = j_corr.iloc[-1, :].mean()\n",
    "#     print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrs[corrs>0.66].iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labled_df = df_norm.T.copy()\n",
    "labled_df['class'] = classes_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74918e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(df_x, df_y_mod.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6adeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_all = pd.DataFrame()\n",
    "\n",
    "for i in range(df_y_mod.shape[1]):\n",
    "    auc_all.loc[0, df_norm.columns[i]] = auc(df_x, df_y_mod.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_norm.T.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma_3.csv', index=None, header=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = pd.DataFrame(columns=['class', 'name'] + list(df_x))\n",
    "# datas['class'] = classes_n\n",
    "# datas['name'] = samle_names\n",
    "# datas.iloc[:, 2:] = df_norm.T.reset_index(drop=True)\n",
    "# datas.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma_2.csv', index=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f9295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568854cf",
   "metadata": {},
   "source": [
    "## avg graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_spectra = pd.DataFrame()\n",
    "groupped_df = labled_df.groupby('class').mean()\n",
    "for i in classes:\n",
    "    mean_spectra[i] = groupped_df.T[i]\n",
    "\n",
    "mean_spectra = mean_spectra.T.copy()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "# a = df_x[1500].index[0]\n",
    "\n",
    "for i in range(8):\n",
    "    plt.plot(df_x, mean_spectra.iloc[i, :]+(5-i)*0.5, c=colors[i], label=mean_spectra.index[i], linewidth=2)\n",
    "    # plt.text(1950, mean_spectra.iloc[i, 494]+(5-i)*0.5, i+1, c='k', fontsize=20 )\n",
    "\n",
    "# plt.xlim((700, 1800))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.title('пмма, раман(785нм)')\n",
    "ax.set_yticklabels([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=25)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "# plt.tick_params(axis='both', which='both', width=2)\n",
    "# plt.legend(bbox_to_anchor=(1.23, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6831d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_spectra = pd.DataFrame()\n",
    "groupped_df = labled_df.groupby('class').mean()\n",
    "for i in classes:\n",
    "    mean_spectra[i] = groupped_df.T[i]\n",
    "\n",
    "mean_spectra = mean_spectra.T.copy()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "# a = df_x[1500].index[0]\n",
    "\n",
    "textt =['4', '6', '8', '10', '12', '14', '16', '0']\n",
    "# textt =['4 мВт', '6 мВт', '8 мВт', '10 мВт', '12 мВт', '14 мВт', '16 мВт', 'пмма']\n",
    "\n",
    "for i in range(8):\n",
    "    if i == 7:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]-3, c=colors[i], label=mean_spectra.index[i], linewidth=2)\n",
    "        plt.text(1940, mean_spectra.iloc[i, 494]-2.9, textt[i], c='k', fontsize=20 )\n",
    "    else:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]-(5-i)*0.5, c=colors[i], label=mean_spectra.index[i], linewidth=2)\n",
    "        plt.text(1940, mean_spectra.iloc[i, 494]-(4.9-i)*0.5, textt[i], c='k', fontsize=20 )\n",
    "\n",
    "# plt.xlim((700, 1800))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.title('пмма, раман(785нм)')\n",
    "ax.set_yticklabels([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=25)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "# plt.tick_params(axis='both', which='both', width=2)\n",
    "# plt.legend(bbox_to_anchor=(1.23, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc618bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_spectra = pd.DataFrame()\n",
    "groupped_df = labled_df.groupby('class').mean()\n",
    "for i in classes:\n",
    "    mean_spectra[i] = groupped_df.T[i]\n",
    "\n",
    "mean_spectra = mean_spectra.T.copy()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "# a = df_x[1500].index[0]\n",
    "\n",
    "for i in range(8):\n",
    "    if i == 7:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]-0.2, c=colors[i], label=mean_spectra.index[i])\n",
    "    elif i == 6:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]+i*0.22, c=colors[i], label=mean_spectra.index[i])\n",
    "    elif i == 0:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]-0.05, c=colors[i], label=mean_spectra.index[i])\n",
    "    elif i == 2:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]+i*0.23, c=colors[i], label=mean_spectra.index[i])\n",
    "    else:\n",
    "        plt.plot(df_x, mean_spectra.iloc[i, :]+i*0.2, c=colors[i], label=mean_spectra.index[i])\n",
    "    # if i < 3 or i == 7:\n",
    "    #     plt.text(1790, mean_spectra.iloc[i, 439], i+1, c='k', fontsize=20)\n",
    "    # else:\n",
    "    #     plt.text(1887, mean_spectra.iloc[i, 467], i+1, c='k', fontsize=20)\n",
    "plt.text(1830, 0.3, 4, c='k', fontsize=20)\n",
    "plt.text(1810, 0.54, 6, c='k', fontsize=20)\n",
    "plt.text(1830, 0.72, 8, c='k', fontsize=20)\n",
    "plt.text(1830, 1.03, 10, c='k', fontsize=20)\n",
    "plt.text(1830, 1.27, 12, c='k', fontsize=20)\n",
    "plt.text(1810, 1.55, 14, c='k', fontsize=20)\n",
    "plt.text(1830, 1.7, 16, c='k', fontsize=20)\n",
    "plt.text(1790, 0.1, 'пмма', c='k', fontsize=20)\n",
    "\n",
    "plt.xlim((1650, 1950))\n",
    "plt.ylim((-.2, 2.9))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.title('пмма, раман(785нм)')\n",
    "ax.set_yticklabels([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=20)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "# plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97419df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(mean_spectra.shape[0]):\n",
    "    # df_sp = pd.concat((pd.Series(df_x), mean_spectra.iloc[i, :].T), axis=1)\n",
    "    # # plt.plot(df_sp.iloc[:, 0], df_sp.iloc[:, 1])\n",
    "    # df_sp.to_csv(rf'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ram\\спектры для диапазона 1650-1950\\{mean_spectra.index[i]}.dat', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(mean_spectra)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_x,\n",
    "        y=mean_spectra.iloc[i, :],  # смещение\n",
    "        mode=\"lines\",\n",
    "        name=classes[i],\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    title=\"Mean spectra by class\",\n",
    "    xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "    yaxis_title=\"a.u.\",\n",
    "    legend_title=\"Классы\"\n",
    ")\n",
    "\n",
    "# Ограничения оси X (как у тебя в комментарии)\n",
    "# fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(mean_spectra)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_x,\n",
    "        y=mean_spectra.iloc[i, :] + (5 - i) * 0.2,  # смещение\n",
    "        mode=\"lines\",\n",
    "        name=classes[i],\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    title=\"Mean spectra by class\",\n",
    "    xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "    yaxis_title=\"a.u.\",\n",
    "    legend_title=\"Классы\"\n",
    ")\n",
    "\n",
    "# Ограничения оси X (как у тебя в комментарии)\n",
    "# fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57816db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.concat((pd.Series(df_x), mean_spectra.iloc[-2, :] - mean_spectra.iloc[-1, :]), axis=1)).to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\6 сем\\data\\1\\diff_sp.csv', sep='\\t', index=None, header=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781c6d",
   "metadata": {},
   "source": [
    "## pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "# pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "pca_1 = pca.fit_transform((df_y_mod.iloc[:, :].T))\n",
    "# pca_1 = pca.fit_transform(StandardScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "# pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "\n",
    "# stsc = StandardScaler().fit_transform(df_y_mod.iloc[:, :].T)\n",
    "# pca_1 = pca.fit_transform(stsc)\n",
    "# pca_1 = pca.fit_transform(pd.concat((df_y_mod.iloc[:3400, :], df_y_mod.iloc[5000:, :]), axis=0).T)\n",
    "\n",
    "pc_1 = 1\n",
    "pc_2 = 2\n",
    "\n",
    "scatter = plt.scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "# plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "values, counts = np.unique(classes_n, return_counts=True)\n",
    "\n",
    "order = np.argsort([classes.index(v) for v in values])\n",
    "values = values[order]\n",
    "counts = counts[order]\n",
    "\n",
    "n_uniq = len(values)\n",
    "cum_sum = np.cumsum(counts)\n",
    "# for i in range(n_uniq):\n",
    "#        if i == 0:\n",
    "#               confidence_ellipse(pca_1[0:cum_sum[i], pc_1-1], pca_1[0:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "#        elif i == 6:\n",
    "#               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=1, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "#        else:\n",
    "#               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "\n",
    "# confidence_ellipse(pca_1[0:15, pc_1-1], pca_1[0:15, pc_2-1], ax, n_std=2, edgecolor=colors[0], facecolor=colors[0], center_color=colors[0], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[15:26, pc_1-1], pca_1[15:26, pc_2-1], ax, n_std=2, edgecolor=colors[1], facecolor=colors[1], center_color=colors[1], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[26:38, pc_1-1], pca_1[26:38, pc_2-1], ax, n_std=2, edgecolor=colors[2], facecolor=colors[2], center_color=colors[2], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[38:46, pc_1-1], pca_1[38:46, pc_2-1], ax, n_std=2, edgecolor=colors[3], facecolor=colors[3], center_color=colors[3], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[46:58, pc_1-1], pca_1[46:58, pc_2-1], ax, n_std=2, edgecolor=colors[4], facecolor=colors[4], center_color=colors[4], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[58:69, pc_1-1], pca_1[58:69, pc_2-1], ax, n_std=2, edgecolor=colors[5], facecolor=colors[5], center_color=colors[5], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[69:82, pc_1-1], pca_1[69:82, pc_2-1], ax, n_std=2, edgecolor=colors[6], facecolor=colors[6], center_color=colors[6], alpha=0.2)\n",
    "# confidence_ellipse(pca_1[82:93, pc_1-1], pca_1[82:93, pc_2-1], ax, n_std=2, edgecolor=colors[7], facecolor=colors[7], center_color=colors[7], alpha=0.2)\n",
    "\n",
    "plt.xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "plt.ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "# plt.xlabel(f'${pc_1}я\\ главная\\ компонента:$ {55.91}%', fontsize=17)\n",
    "# plt.ylabel(f'${pc_2}я\\ главная\\ компонента:$ {16.38}%', fontsize=17)\n",
    "# plt.title('$PCA,\\ раман$')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "                          markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "                   for cls, color in colors_n.items()]\n",
    "\n",
    "# plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# pca = PCA(n_components=20)\n",
    "# # pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "# # pca_1 = pca.fit_transform((df_y_mod.iloc[:, :].T))\n",
    "# # pca_1 = pca.fit_transform(StandardScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "# pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "\n",
    "# # stsc = StandardScaler().fit_transform(df_y_mod.iloc[:, :].T)\n",
    "# # pca_1 = pca.fit_transform(stsc)\n",
    "# # pca_1 = pca.fit_transform(pd.concat((df_y_mod.iloc[:3400, :], df_y_mod.iloc[5000:, :]), axis=0).T)\n",
    "\n",
    "# pc_1 = 1\n",
    "# pc_2 = 2\n",
    "\n",
    "# scatter = plt.scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "# # plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "# values, counts = np.unique(classes_n, return_counts=True)\n",
    "\n",
    "# order = np.argsort([classes.index(v) for v in values])\n",
    "# values = values[order]\n",
    "# counts = counts[order]\n",
    "\n",
    "# n_uniq = len(values)\n",
    "# cum_sum = np.cumsum(counts)\n",
    "# for i in range(n_uniq):\n",
    "#        if i == 0:\n",
    "#               confidence_ellipse(pca_1[0:cum_sum[i], pc_1-1], pca_1[0:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=textt[i])\n",
    "#        elif i == 6:\n",
    "#               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=1, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=textt[i])\n",
    "#        else:\n",
    "#               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=textt[i])\n",
    "\n",
    "# # confidence_ellipse(pca_1[0:15, pc_1-1], pca_1[0:15, pc_2-1], ax, n_std=2, edgecolor=colors[0], facecolor=colors[0], center_color=colors[0], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[15:26, pc_1-1], pca_1[15:26, pc_2-1], ax, n_std=2, edgecolor=colors[1], facecolor=colors[1], center_color=colors[1], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[26:38, pc_1-1], pca_1[26:38, pc_2-1], ax, n_std=2, edgecolor=colors[2], facecolor=colors[2], center_color=colors[2], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[38:46, pc_1-1], pca_1[38:46, pc_2-1], ax, n_std=2, edgecolor=colors[3], facecolor=colors[3], center_color=colors[3], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[46:58, pc_1-1], pca_1[46:58, pc_2-1], ax, n_std=2, edgecolor=colors[4], facecolor=colors[4], center_color=colors[4], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[58:69, pc_1-1], pca_1[58:69, pc_2-1], ax, n_std=2, edgecolor=colors[5], facecolor=colors[5], center_color=colors[5], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[69:82, pc_1-1], pca_1[69:82, pc_2-1], ax, n_std=2, edgecolor=colors[6], facecolor=colors[6], center_color=colors[6], alpha=0.2)\n",
    "# # confidence_ellipse(pca_1[82:93, pc_1-1], pca_1[82:93, pc_2-1], ax, n_std=2, edgecolor=colors[7], facecolor=colors[7], center_color=colors[7], alpha=0.2)\n",
    "\n",
    "# # plt.xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "# # plt.ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "# plt.xlabel(f'${pc_1}я\\ главная\\ компонента:$ {55.91}%', fontsize=17)\n",
    "# plt.ylabel(f'${pc_2}я\\ главная\\ компонента:$ {16.38}%', fontsize=17)\n",
    "# # plt.title('$PCA,\\ раман$')\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=15)\n",
    "\n",
    "# legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "#                           markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "#                    for cls, color in colors_n.items()]\n",
    "\n",
    "# # plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eeef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls_binary = PLSRegression(n_components=10)\n",
    "# # Fit and transform the data\n",
    "# # X_pls = pls_binary.fit_transform(df_y_mod.T, classes_mw)[0]\n",
    "# X_pls = pls_binary.fit_transform(StandardScaler().fit_transform(df_y_mod).T, classes_mw)[0]\n",
    "\n",
    "# pc_1 = 1\n",
    "# pc_2 = 2\n",
    "\n",
    "# plt.scatter(X_pls[:, pc_1-1], X_pls[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "# # for i in range(10):\n",
    "# #     plt.scatter(X_pls[0+10*i:10+10*i, 1], X_pls[0+10*i:10+10*i, 2], c=colors[i], s=100, edgecolors='k')\n",
    "# #     plt.text(np.mean(X_pls[0+10*i:10+10*i, 1]), np.mean(X_pls[0+10*i:10+10*i, 2]), paper_Y[i], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "# plt.xlabel('Latent Variable 1')\n",
    "# plt.ylabel('Latent Variable 2')\n",
    "# # plt.legend(labplot,loc='lower left')\n",
    "# plt.title('PLS, Raman')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67673f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# # PCA\n",
    "# pca = PCA(n_components=10)\n",
    "# pca_1 = pca.fit_transform(df_y_mod.T)  # Транспонируем, как у тебя\n",
    "\n",
    "# pc_1 = 1\n",
    "# pc_2 = 2\n",
    "\n",
    "# # Делаем DataFrame для удобства\n",
    "# df_plot = pd.DataFrame({\n",
    "#     f\"PC{pc_1}\": pca_1[:, pc_1-1],\n",
    "#     f\"PC{pc_2}\": pca_1[:, pc_2-1],\n",
    "#     \"class\": [cls for cls in colors_for_points],  # твоя раскраска\n",
    "#     'name': samle_names\n",
    "# })\n",
    "\n",
    "# # Рисуем\n",
    "# fig = px.scatter(\n",
    "#     df_plot,\n",
    "#     x=f\"PC{pc_1}\",\n",
    "#     y=f\"PC{pc_2}\",\n",
    "#     color=\"class\",\n",
    "#     title=\"PCA\",\n",
    "#     hover_name='name',\n",
    "#     labels={\n",
    "#         f\"PC{pc_1}\": f\"PC{pc_1} ({pca.explained_variance_ratio_[pc_1-1]*100:.2f}%)\",\n",
    "#         f\"PC{pc_2}\": f\"PC{pc_2} ({pca.explained_variance_ratio_[pc_2-1]*100:.2f}%)\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# fig.update_traces(marker=dict(size=12, line=dict(width=1, color='black')))\n",
    "# fig.update_layout(legend_title=\"Классы\")\n",
    "\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components = 10\n",
    "\n",
    "# # total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "\n",
    "# labels = {str(i): f\"PC {i+1}\" for i in range(n_components)}\n",
    "\n",
    "# fig = px.scatter_matrix(\n",
    "#     pca_1,\n",
    "#     # color = colors_for_points,\n",
    "#     # color=c_selected,\n",
    "#     color=classes_n,\n",
    "#     color_discrete_map=colors_n,\n",
    "#     dimensions=range(n_components),\n",
    "#     labels=labels,\n",
    "#     # title=f'Total Explained Variance: {total_var:.2f}%', \n",
    "#     width=2500, height=2000\n",
    "# )\n",
    "\n",
    "# # fig.update_layout(plot_bgcolor='white' )\n",
    "# # fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightPink')\n",
    "# # fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightPink')\n",
    "# # fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "# # fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightPink')\n",
    "\n",
    "\n",
    "# fig.update_traces(diagonal_visible=False)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# # embedding = umap.UMAP(n_neighbors=7, random_state=152).fit_transform(df_norm.iloc[:, :].T)\n",
    "# embedding = umap.UMAP(n_neighbors=7, random_state=2).fit_transform(df_y_mod.iloc[:, :].T)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=colors_for_points , s=100, edgecolors='k')\n",
    "# # scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=c_selected , s=100, edgecolors='k')\n",
    "# legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "#                           markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "#                    for cls, color in colors_n.items()]\n",
    "\n",
    "# plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcs_1 = pd.concat((pd.Series(df_x), pd.Series(pca.components_[pc_1-1])), axis=1)\n",
    "# pcs_1\n",
    "# pcs_1.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ram\\785 loading\\pc_1.dat', sep='\\t', index=None, header=None)\n",
    "\n",
    "# pcs_2 = pd.concat((pd.Series(df_x), pd.Series(pca.components_[pc_2-1])), axis=1)\n",
    "# pcs_2\n",
    "# pcs_2.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ram\\785 loading\\pc_2.dat', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055be379",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "pc_1 = 1\n",
    "pc_2 = 2\n",
    "pc_3 = 4\n",
    "\n",
    "# pca_1 = pca.fit_transform(df_norm.iloc[:, :].T)\n",
    "\n",
    "# pca.components_[pc_1-1, :1300] = pca.components_[pc_1-1, :1300]/1.7\n",
    "# pca.components_[pc_2-1, :1300] = pca.components_[pc_2-1, :1300]/1.7\n",
    "# pca.components_[pc_3-1, :1300] = pca.components_[pc_3-1, :1300]/1.7\n",
    "\n",
    "plt.plot(df_x, gaussian_filter1d(pca.components_[pc_1-1], 2), label=f'pc {pc_1}')\n",
    "# plt.plot(df_x, savgol_filter(pca.components_[pc_1-1], 95, 3), label=f'pc {pc_1}')\n",
    "plt.plot(df_x, gaussian_filter1d(pca.components_[pc_2-1], 2), label=f'pc {pc_2}')\n",
    "plt.axhline(0, color=\"black\", linewidth=1, linestyle=\"--\")\n",
    "# plt.plot(df_x, gaussian_filter1d(pca.components_[pc_3-1], 2), label=f'pc {pc_3}')\n",
    "\n",
    "plt.text(1600, 0.065, 1, c= 'k', fontsize=23)\n",
    "plt.text(1600, -0.04, 2, c='k', fontsize=23)\n",
    "\n",
    "# plt.plot(IR_1800_x.iloc[:], pca.components_[pc_1-1], label=f'pc {pc_1}')\n",
    "# plt.plot(IR_1800_x.iloc[:], pca.components_[pc_2-1], label=f'pc {pc_2}')\n",
    "# plt.plot(IR_1800_x.iloc[:], pca.components_[pc_3-1], label=f'pc {pc_3}')\n",
    "\n",
    "# plt.xlim([800, 4000])\n",
    "# plt.legend()\n",
    "# ax.set_xticks(np.arange(800, 4000, 300))\n",
    "# ax.set_yticklabels([])\n",
    "\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=20)\n",
    "plt.ylabel('$Нагрузки\\ главных\\ компонент,\\ усл.\\ ед.$', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "n_comps = 10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "plt.bar(range(1, n_comps+1), pca.explained_variance_ratio_[:n_comps], align='center',\n",
    "        label='доля дисперсии описанной отдельной компоненты', color = 'lightsalmon')\n",
    "\n",
    "for x, y in zip(range(1, n_comps+1), expl_var[:n_comps]):\n",
    "    ax.annotate(f\"{round(y * 100):.0f}%\", (x - 0.1, y - 0.07), fontsize=13)\n",
    "\n",
    "plt.plot(range(1, n_comps+1), expl_var[:n_comps], label='Куммулятивная объясненная дисперсия', marker=\"o\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.xlabel(f'Главные компоненты', fontsize=15)\n",
    "plt.ylabel(f'Объясненная дисперсия', fontsize=15)\n",
    "# plt.title('Куммулятивная объясненная дисперсия')\n",
    "\n",
    "plt.xticks(range(1, n_comps+1), fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "# plt.legend(loc='center right', fontsize=13)\n",
    "plt.text(2.3, 0.8, 1, c= 'k', fontsize=20)\n",
    "plt.text(2.3, 0.18, 2, c='k', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = 6\n",
    "rows = 3\n",
    "cols = math.ceil(nums / rows)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "for i in range(nums):\n",
    "    # axes[i].plot(df_x, gaussian_filter1d(pca.components_[i], 10), label=f\"Компонента {i + 1}\")\n",
    "    axes[i].plot(df_x, pca.components_[i], label=f\"Компонента {i + 1}\")\n",
    "    axes[i].axhline(0, color=\"black\", linewidth=1, linestyle=\"--\")\n",
    "    axes[i].set_title(f\"Компонента {i + 1}: {pca.explained_variance_ratio_[i]*100:.2f}%\")\n",
    "    axes[i].grid(True)\n",
    "    ax2 = axes[i].twinx()\n",
    "    ax2.plot(df_x, mean_spectra.iloc[-1, :], color=\"red\", linestyle=\"-\", label=\"pmma\", alpha=0.4)\n",
    "    axes[i].minorticks_on()\n",
    "    axes[i].grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.5)\n",
    "    lines1, labels1 = axes[i].get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    axes[i].legend( lines1 + lines2, labels1 + labels2,)\n",
    "fig.suptitle('pca компоненты рамана снятого на 785 нм')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131194d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes_to_select = ['pmma_4_mw', 'pmma_6_mw', 'pmma_8_mw', 'pmma_10_mw', 'pmma_12_mw', 'pmma_14_mw', 'pmma_16_mw']\n",
    "\n",
    "# selected_columns = [col for col in df_norm.columns if any(col.startswith(cls) for cls in classes_to_select)]\n",
    "# # subset_names = [col for col in df_norm.columns if any(col.startswith(cls) for cls in classes_to_select)]\n",
    "\n",
    "# c_selected = [i for en,i in enumerate(colors_for_points) if en<82]\n",
    "\n",
    "# df_subset = df_norm.iloc[:, :82]\n",
    "# # df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac65ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# pca = PCA(n_components=10)\n",
    "# pca_1 = pca.fit_transform(df_subset.iloc[:, :].T) #1195\n",
    "\n",
    "# pc_1 = 1\n",
    "# pc_2 = 2\n",
    "\n",
    "# scatter = plt.scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=c_selected , s=100, edgecolors='k')\n",
    "# # plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "# # confidence_ellipse(pca_1[0+10*i:10+10*i, pc_1-1], pca_1[0+10*i:10+10*i, pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.2)\n",
    "\n",
    "# plt.xlabel(f'${pc_1}\\ pc:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%')\n",
    "# plt.ylabel(f'${pc_2}\\ pc:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%')\n",
    "# plt.title('$PCA$')\n",
    "\n",
    "# legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "#                           markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "#                    for cls, color in colors_n.items()]\n",
    "\n",
    "# plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# pca = PCA(n_components=10)\n",
    "# pca_1 = pca.fit_transform(df_subset.iloc[:, :].T) #1195\n",
    "\n",
    "# pc_1 = 1\n",
    "# pc_2 = 2\n",
    "\n",
    "# plt.scatter(pca_1[:10, pc_1-1], pca_1[:10, pc_2-1], c=colors[0], s=100, edgecolors='k', label='pmma_16_mw')\n",
    "# plt.scatter(pca_1[10:, pc_1-1], pca_1[10:, pc_2-1], c=colors[1], s=100, edgecolors='k', label='pmma_16_mw_rev')\n",
    "# # plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "# # confidence_ellipse(pca_1[0+10*i:10+10*i, pc_1-1], pca_1[0+10*i:10+10*i, pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.2)\n",
    "\n",
    "# plt.xlabel(f'${pc_1}\\ pc:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%')\n",
    "# plt.ylabel(f'${pc_2}\\ pc:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%')\n",
    "# plt.title('$PCA$')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e940a1f",
   "metadata": {},
   "source": [
    "## diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_spectra = pd.DataFrame()\n",
    "for i in range(df_norm.shape[1]):\n",
    "    diff_spectra[samle_names[i]] = df_norm[samle_names[i]] - mean_spectra.T['pmma_clean_pmma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_x, diff_spectra.iloc[:, :])\n",
    "\n",
    "\n",
    "plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "plt.ylabel('$a.u.$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa819448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labled_diff_df = diff_spectra.T.copy()\n",
    "labled_diff_df['class'] = classes_n\n",
    "\n",
    "mean_diff_spectra = pd.DataFrame()\n",
    "groupped_diff_df = labled_diff_df.groupby('class').mean()\n",
    "for i in classes:\n",
    "    mean_diff_spectra[i] = groupped_diff_df.T[i]\n",
    "\n",
    "mean_diff_spectra = mean_diff_spectra.T.copy()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "# a = df_x[1500].index[0]\n",
    "\n",
    "for i in range(7):\n",
    "    plt.plot(df_x, mean_diff_spectra.iloc[i, :]-(5.1-i)*0.2, c=colors[i], label=mean_diff_spectra.index[i], linewidth=2)\n",
    "    # plt.axhline((5-i)*0.2, color=colors[i], linewidth=1, linestyle=\"--\", alpha=0.5)\n",
    "    # plt.text(1650, 0-(5-i)*0.5, classes[i], c='k' )\n",
    "plt.text(2000, 0.25, '16', c='k', fontsize=20)\n",
    "plt.text(2000, 0, '14', c='k', fontsize=20)\n",
    "plt.text(2000, -0.2, '12', c='k', fontsize=20)\n",
    "plt.text(2000, -0.37, '10', c='k', fontsize=20)\n",
    "plt.text(2000, -0.6, '8', c='k', fontsize=20)\n",
    "plt.text(2000, -0.8, '6', c='k', fontsize=20)\n",
    "plt.text(2000, -0.99, '4', c='k', fontsize=20)\n",
    "\n",
    "# plt.xlim((700, 1800))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.grid(alpha=0.3, which='both')\n",
    "# plt.minorticks_on()\n",
    "plt.yticks([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=25)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=25)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(mean_diff_spectra.shape[0]-1):\n",
    "#     df_sp = pd.concat((pd.Series(df_x), mean_diff_spectra.iloc[i, :].T), axis=1)\n",
    "#     # plt.plot(df_sp.iloc[:, 0], df_sp.iloc[:, 1])\n",
    "#     df_sp.to_csv(rf'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ram\\разностные спектры\\{mean_diff_spectra.index[i]}.dat', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labled_diff_df = diff_spectra.T.copy()\n",
    "labled_diff_df['class'] = classes_n\n",
    "\n",
    "mean_diff_spectra = pd.DataFrame()\n",
    "groupped_diff_df = labled_diff_df.groupby('class').mean()\n",
    "for i in classes:\n",
    "    mean_diff_spectra[i] = groupped_diff_df.T[i]\n",
    "\n",
    "mean_diff_spectra = mean_diff_spectra.T.copy()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "# a = df_x[1500].index[0]\n",
    "\n",
    "for i in range(7):\n",
    "    plt.plot(df_x, mean_diff_spectra.iloc[i, :], c=colors[i], label=mean_diff_spectra.index[i], linewidth=2)\n",
    "    \n",
    "    # plt.text(1650, df_means_smooth.iloc[660, i]+(5-i)*0.5, classes[i], c='k' )\n",
    "# plt.axhline(0,  color='b', linewidth=1, linestyle=\"--\", alpha=0.5)\n",
    "ax.plot([300, 2000], [0, 0], color='k', linewidth=2, linestyle='--', alpha=0.5)\n",
    "\n",
    "# plt.text(1650, mean_diff_spectra.iloc[0, 397], 1, c= 'k', fontsize=17)\n",
    "# plt.text(1650, mean_diff_spectra.iloc[1, 397], 2, c='k', fontsize=17)\n",
    "# plt.text(1650, mean_diff_spectra.iloc[2, 397]-0.03, 3, c='k', fontsize=17)\n",
    "# plt.text(1520, mean_diff_spectra.iloc[3, 368]+0.35, 4, c='k', fontsize=17)\n",
    "# plt.text(1520, mean_diff_spectra.iloc[4, 368]+0.4, 5, c='k', fontsize=17)\n",
    "# plt.text(1520, mean_diff_spectra.iloc[5, 368]+0.37, 6, c='k', fontsize=17)\n",
    "# plt.text(1520, mean_diff_spectra.iloc[6, 368]+0.45, 7, c='k', fontsize=17)\n",
    "\n",
    "arrow_kw = dict(arrowstyle='-', color='k', lw=1.5, shrinkA=0, shrinkB=0)\n",
    "\n",
    "\n",
    "x2 = df_x.iloc[335] if hasattr(df_x, \"iloc\") else df_x[335]\n",
    "ax.annotate('1', xy=(1555, 0.1), xytext=(1470, -0.07),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "ax.annotate('2', xy=(1590, 0.04), xytext=(1470, -0.14),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "ax.annotate('3', xy=(1660, -0.03), xytext=(1470, -0.2),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "ax.annotate('4', xy=(x2, mean_diff_spectra.iloc[3, 334]), xytext=(1520, mean_diff_spectra.iloc[3, 368]+0.35),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "ax.annotate('5', xy=(x2, mean_diff_spectra.iloc[4, 335]), xytext=(1520, mean_diff_spectra.iloc[4, 368]+0.40),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "ax.annotate('6', xy=(x2, mean_diff_spectra.iloc[5, 335]), xytext=(1520, mean_diff_spectra.iloc[5, 368]+0.37),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "ax.annotate('7', xy=(x2, mean_diff_spectra.iloc[6, 342]), xytext=(1520, mean_diff_spectra.iloc[6, 368]+0.45),\n",
    "            textcoords='data', fontsize=17, color='k', ha='left', va='center',\n",
    "            arrowprops=arrow_kw)\n",
    "\n",
    "# plt.xlim((700, 1800))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.grid(alpha=0.3, which='both')\n",
    "# plt.minorticks_on()\n",
    "# ax.set_yticklabels([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=20)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_diff_spectra_mod = mean_diff_spectra.T.copy()\n",
    "# mean_diff_spectra_mod.set_index(df_x, inplace=True)  \n",
    "# mean_diff_spectra_mod.to_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\6 сем\\data\\5\\mean_diff_spectra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "\n",
    "# for i in range(len(mean_diff_spectra)):\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=df_x,\n",
    "#         y=mean_diff_spectra.iloc[i, :] + (5 - i) * 0.2,  # смещение\n",
    "#         mode=\"lines\",\n",
    "#         name=classes[i],\n",
    "#         line=dict(color=colors[i])\n",
    "#     ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     width=800,\n",
    "#     height=800,\n",
    "#     title=\"Mean spectra by class\",\n",
    "#     xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "#     yaxis_title=\"a.u.\",\n",
    "#     legend_title=\"Классы\"\n",
    "# )\n",
    "\n",
    "# # fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(mean_diff_spectra)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_x,\n",
    "        y=mean_diff_spectra.iloc[i, :],  \n",
    "        mode=\"lines\",\n",
    "        name=classes[i],\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=800,\n",
    "    title=\"Mean spectra by class\",\n",
    "    xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "    yaxis_title=\"a.u.\",\n",
    "    legend_title=\"Классы\"\n",
    ")\n",
    "\n",
    "# Ограничения оси X (как у тебя в комментарии)\n",
    "# fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(mean_diff_spectra)):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_x,\n",
    "        y=mean_diff_spectra.iloc[i, :] * 100 / mean_spectra.iloc[-1, :] ,  \n",
    "        mode=\"lines\",\n",
    "        name=classes[i],\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    # yaxis=dict(range=[0, 100]),\n",
    "    title=\"Mean spectra by class\",\n",
    "    xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "    yaxis_title=\"a.u.\",\n",
    "    legend_title=\"Классы\"\n",
    ")\n",
    "\n",
    "# fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4690c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_x, mean_diff_spectra.iloc[-2, :] * 100 / mean_spectra.iloc[-1, :]) # \n",
    "# plt.plot(df_x, mean_spectra.iloc[-2, :]) \n",
    "# plt.plot(df_x, mean_spectra.iloc[-1, :])\n",
    "plt.axhline(0)\n",
    "plt.ylim(top=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50797e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_1 = pca.fit_transform(diff_spectra.iloc[:, :].T) #1195\n",
    "\n",
    "pc_1 = 1\n",
    "pc_2 = 2\n",
    "\n",
    "scatter = plt.scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "# plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "# confidence_ellipse(pca_1[0+10*i:10+10*i, pc_1-1], pca_1[0+10*i:10+10*i, pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.2)\n",
    "\n",
    "plt.xlabel(f'${pc_1}\\ pc:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%')\n",
    "plt.ylabel(f'${pc_2}\\ pc:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%')\n",
    "plt.title('$PCA$')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "                          markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "                   for cls, color in colors_n.items()]\n",
    "\n",
    "plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a21e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = 6\n",
    "rows = 2\n",
    "cols = math.ceil(nums / rows)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "for i in range(nums):\n",
    "    axes[i].plot(df_x, gaussian_filter1d(pca.components_[i], 0.1), label=f\"Компонента {i + 1}\")\n",
    "    axes[i].axhline(0, color=\"black\", linewidth=1, linestyle=\"--\")\n",
    "    axes[i].set_title(f\"Компонента {i + 1}: {pca.explained_variance_ratio_[i]*100:.2f}%\")\n",
    "    axes[i].grid(True)\n",
    "    ax2 = axes[i].twinx()\n",
    "    ax2.plot(df_x, mean_spectra.iloc[-1, :], color=\"red\", linestyle=\"-\", label=\"pmma\", alpha=0.4)\n",
    "    axes[i].minorticks_on()\n",
    "    axes[i].grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.5)\n",
    "    lines1, labels1 = axes[i].get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    axes[i].legend( lines1 + lines2, labels1 + labels2,)\n",
    "    fig.suptitle('pca компоненты рамана снятого на 785 нм')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71472ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mw(name: str) -> int:\n",
    "    if \"clean\" in name:\n",
    "        return 0\n",
    "    match = re.search(r'_(\\d+)_mw', name)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "classes_mw = [extract_mw(s) for s in classes_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3822006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = np.asarray(classes_mw) \n",
    "# corr = {}\n",
    "\n",
    "# for i, name in enumerate(df_smooth.columns):\n",
    "#     y = df_smooth.iloc[:, i].to_numpy()\n",
    "#     corr[name] = np.corrcoef(v, y)[0, 1]\n",
    "\n",
    "# corr = pd.Series(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_series = pd.Series(classes_mw, index=df_y_mod.T.index)\n",
    "\n",
    "# corr = df_smooth.corrwith(df_y_mod.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60946d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_series = df_y_mod.copy()\n",
    "v_series.loc[501, :] = classes_mw\n",
    "correl = v_series.T.corr()\n",
    "plt.plot(correl.loc[501, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7160be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(new_x, correl.loc[501, 0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6597986",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl.loc[501, 0:500].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5504f",
   "metadata": {},
   "source": [
    "## lin reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_y_mod.loc[66,:], classes_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "idx = correl.loc[501, 0:500][(correl.loc[501, 0:500]) > threshold].index\n",
    "idx.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx)\n",
    "print(new_x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = len(idx)\n",
    "rows = 3\n",
    "cols = math.ceil(nums / rows)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "for en,i in enumerate(idx):\n",
    "    axes[en].scatter(df_y_mod.loc[i,:], classes_mw)\n",
    "    axes[en].set_xlabel(r'$a.u. величина\\ пика, корр: $', )\n",
    "    axes[en].set_ylabel(r'$mw$')\n",
    "    axes[en].set_title(f'wavenumber - {new_x[i]}')\n",
    "    # k, b = np.polyfit(df_y_mod.loc[i,:], classes_mw, 1)\n",
    "    # y_fit = k * df_y_mod.loc[i,:] + b\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_y_mod.loc[430, :'pmma_16_mw_8'], classes_mw[0:-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125363e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a259ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddt = pd.concat((df_y_mod.loc[430, :'pmma_16_mw_8'].reset_index(drop=True), pd.Series(classes_mw[0:-11])), axis=1)\n",
    "ddt.columns = [\"intensity\", \"mW\"]\n",
    "ddt_means = ddt.groupby(\"mW\").mean()\n",
    "\n",
    "linreg = LinearRegression().fit(X=ddt_means.values, y=ddt_means.index)\n",
    "linreg_1 = linreg.predict(ddt_means.values)\n",
    "\n",
    "classes_sorted = np.sort(ddt[\"mW\"].unique())\n",
    "box_data = [ddt.loc[ddt[\"mW\"] == c, \"intensity\"].values for c in classes_sorted]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "plt.boxplot(box_data, vert=True, positions=classes_sorted, widths=0.6, manage_ticks=False, showfliers=False)\n",
    "# plt.scatter(ddt_means.values, ddt_means.index)\n",
    "plt.plot(linreg_1, ddt_means.values, color='r' )\n",
    "plt.ylabel('$Интенсивность\\ пика\\ 1765\\ см^{-1},\\ усл.\\ ед.$', fontsize=20)\n",
    "plt.xlabel('$Мощность\\ лазера,\\ мВт$', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# plt.title(f'$R^{2}={np.round(r2_score(ddt_means.index, linreg_1), 2)},\\ corr={np.round(np.corrcoef(ddt_means.index.T, linreg_1.T)[0, 1], 2)}$')\n",
    "plt.show()\n",
    "# label=f'$R^{2}={np.round(r2_score(i_380c, linreg_1), 2)},\\ corr={np.round(np.corrcoef(i_380c.T, linreg_1.T)[0, 1], 2)}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2cee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddt = pd.concat((df_y_mod.loc[305, :'pmma_16_mw_8'].reset_index(drop=True), pd.Series(classes_mw[0:-11])), axis=1)\n",
    "ddt.columns = [\"intensity\", \"mW\"]\n",
    "ddt_means = ddt.groupby(\"mW\").mean()\n",
    "\n",
    "linreg = LinearRegression().fit(X=ddt_means.values, y=ddt_means.index)\n",
    "linreg_1 = linreg.predict(ddt_means.values)\n",
    "\n",
    "classes_sorted = np.sort(ddt[\"mW\"].unique())\n",
    "box_data = [ddt.loc[ddt[\"mW\"] == c, \"intensity\"].values for c in classes_sorted]\n",
    "\n",
    "plt.boxplot(box_data, vert=True, positions=classes_sorted, widths=0.6, manage_ticks=False, showfliers=False)\n",
    "# plt.scatter(ddt_means.values, ddt_means.index)\n",
    "plt.plot(linreg_1, ddt_means.values, color='r' )\n",
    "plt.ylabel(f'интенсивность пика {df_x[305]}')\n",
    "plt.xlabel('mW')\n",
    "plt.title(f'$R^{2}={np.round(r2_score(ddt_means.index, linreg_1), 2)},\\ corr={np.round(np.corrcoef(ddt_means.index.T, linreg_1.T)[0, 1], 2)}$')\n",
    "plt.show()\n",
    "# label=f'$R^{2}={np.round(r2_score(i_380c, linreg_1), 2)},\\ corr={np.round(np.corrcoef(i_380c.T, linreg_1.T)[0, 1], 2)}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c721947",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_y_mod.T[345] >= 1.9\n",
    "df_y_mod.T[mask]\n",
    "df_y_mod.T.iloc[np.where(mask)[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fea7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(classes_mw) == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffeb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddt = pd.concat((df_y_mod.loc[420, :'pmma_16_mw_8'].reset_index(drop=True), pd.Series(classes_mw[0:-11])), axis=1)\n",
    "ddt = ddt.groupby(0).mean()\n",
    "\n",
    "linreg = LinearRegression().fit(X=ddt.values, y=ddt.index)\n",
    "linreg_1 = linreg.predict(ddt.values)\n",
    "plt.scatter(ddt.values, ddt.index)\n",
    "plt.plot(ddt.values, linreg_1, color='r' )\n",
    "plt.xlabel('интенсивность пика 1730')\n",
    "plt.ylabel('mW')\n",
    "plt.title(f'$R^{2}={np.round(r2_score(ddt.index, linreg_1), 2)},\\ corr={np.round(np.corrcoef(ddt.index.T, linreg_1.T)[0, 1], 2)}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aab646",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_y_mod.loc[421, :], df_y_mod.loc[306, :], c=colors_for_points , s=100, edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40970d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.imshow(correl.loc[501, 0:500], aspect=\"auto\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Correlation\")\n",
    "plt.yticks([])\n",
    "plt.xticks(range(len(correl.loc[501, 0:500])), correl.loc[501, 0:500].index, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75083816",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40122051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca_1 = pca.fit_transform(diff_spectra.T)  # Транспонируем, как у тебя\n",
    "\n",
    "pc_1 = 1\n",
    "pc_2 = 2\n",
    "\n",
    "# Делаем DataFrame для удобства\n",
    "df_plot = pd.DataFrame({\n",
    "    f\"PC{pc_1}\": pca_1[:, pc_1-1],\n",
    "    f\"PC{pc_2}\": pca_1[:, pc_2-1],\n",
    "    \"class\": [cls for cls in colors_for_points],  # твоя раскраска\n",
    "    'name': samle_names\n",
    "})\n",
    "\n",
    "# Рисуем\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=f\"PC{pc_1}\",\n",
    "    y=f\"PC{pc_2}\",\n",
    "    color=\"class\",\n",
    "    title=\"PCA\",\n",
    "    hover_name='name',\n",
    "    labels={\n",
    "        f\"PC{pc_1}\": f\"PC{pc_1} ({pca.explained_variance_ratio_[pc_1-1]*100:.2f}%)\",\n",
    "        f\"PC{pc_2}\": f\"PC{pc_2} ({pca.explained_variance_ratio_[pc_2-1]*100:.2f}%)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=1, color='black')))\n",
    "fig.update_layout(legend_title=\"Классы\")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_spectra(df, x=None, title=\"\"):\n",
    "    \"\"\"\n",
    "    df : pd.DataFrame\n",
    "        Таблица, где каждая колонка = один спектр.\n",
    "    x : массив или список\n",
    "        Значения по оси X (например, длина волны). Если None -> используется индекс df.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",       \n",
    "        xaxis=dict(\n",
    "        # showline=True,\n",
    "        # linecolor=\"black\",\n",
    "        # linewidth=2,\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgray\",  \n",
    "        zeroline=False,\n",
    "        minor=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor=\"gainsboro\",  \n",
    "            dtick=50 )                      \n",
    "        ),\n",
    "        yaxis=dict(\n",
    "        # showline=True,\n",
    "        # linecolor=\"black\",\n",
    "        # linewidth=2,\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgray\",\n",
    "        zeroline=False,\n",
    "        minor=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor=\"gainsboro\",\n",
    "            dtick=0.1  )\n",
    "        ),\n",
    "        width=900,   \n",
    "        height=600,\n",
    "        margin=dict(\n",
    "            l=50,   \n",
    "            r=50,   \n",
    "            t=80,   \n",
    "            b=60    \n",
    "    )\n",
    ")\n",
    "    \n",
    "    if x is None:\n",
    "        x = df.index\n",
    "    \n",
    "    for col in df.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=df[col],\n",
    "            mode=\"lines\",\n",
    "            name=str(col),\n",
    "            hoverinfo=\"name\"\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"$wavenumber, cm^{-1}$\",\n",
    "        yaxis_title=\"Интенсивность\",\n",
    "        hovermode=\"closest\"\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618172af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra(diff_spectra, df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981788ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=df_x, y=diff_spectra.iloc[:, 55], mode='lines'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 4], mode='lines'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 9], mode='lines'), secondary_y=True)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 10], mode='lines'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 4] - df_f.iloc[:, 10], mode='lines'), secondary_y=False)\n",
    "# for i in range(10, 14):\n",
    "#     fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, i], mode='lines', line=dict(color=\"#4361ee\")), secondary_y=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=10, r=10, t=10, b=20), width=1400, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for en,i in enumerate(samle_names):\n",
    "    if i == 'pmma_clean_pmma_12':\n",
    "        print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rubberband(x, y):\n",
    "    # Находим выпуклую оболочку\n",
    "    v = ConvexHull(np.column_stack([x, y])).vertices\n",
    "    v = np.roll(v, -v.argmin())  # начинаем с минимального индекса\n",
    "    base = v[:v.argmax()+1]      # нижняя часть оболочки\n",
    "    baseline = interp1d(x[base], y[base], kind='linear', fill_value=\"extrapolate\")(x)\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d33851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def rubberband(x, y):\n",
    "    \"\"\"\n",
    "    Построение baseline методом rubber band для одного спектра\n",
    "    \"\"\"\n",
    "    # построим выпуклую оболочку\n",
    "    v = ConvexHull(np.column_stack([x, y])).vertices\n",
    "    v = np.roll(v, -v.argmin())  # начать с минимального индекса\n",
    "    base = v[:v.argmax()+1]      # нижняя часть оболочки\n",
    "    \n",
    "    # интерполяция baseline\n",
    "    baseline = interp1d(x[base], y[base], kind='linear', fill_value=\"extrapolate\")(x)\n",
    "    return baseline\n",
    "\n",
    "def rubberband_correction(df):\n",
    "    \"\"\"\n",
    "    df: DataFrame (index = x, columns = спектры)\n",
    "    Возвращает скорректированный DataFrame\n",
    "    \"\"\"\n",
    "    x = df.index.to_numpy()\n",
    "    corrected = {}\n",
    "    for col in df.columns:\n",
    "        y = df[col].to_numpy()\n",
    "        baseline = rubberband(x, y)\n",
    "        corrected[col] = y - baseline\n",
    "    return pd.DataFrame(corrected, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rubberband_baseline(x, y, n_baseline_points=64):\n",
    "    \"\"\"\n",
    "    Rubberband correction с фиксированным числом baseline точек.\n",
    "    \n",
    "    x : np.array — ось спектра\n",
    "    y : np.array — спектр\n",
    "    n_baseline_points : int — количество точек, используемых для baseline\n",
    "    \"\"\"\n",
    "    # Выбираем индексы baseline точек равномерно\n",
    "    idx = np.linspace(0, len(x)-1, n_baseline_points, dtype=int)\n",
    "    x_baseline = x[idx]\n",
    "    y_baseline = y[idx]\n",
    "    \n",
    "    # Интерполяция baseline\n",
    "    baseline = interp1d(x_baseline, y_baseline, kind='linear', fill_value=\"extrapolate\")(x)\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adada54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "\n",
    "def concave_rubberband(x, y):\n",
    "    # ищем локальные минимумы\n",
    "    y = np.array(y)\n",
    "    minima_idx = argrelextrema(y, np.less)[0]\n",
    "    # добавляем крайние точки\n",
    "    minima_idx = np.concatenate([[0], minima_idx, [len(y)-1]])\n",
    "    baseline = np.interp(x, x[minima_idx], y[minima_idx])\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def concave_rubberband_baseline(x, y, n_baseline_points=64):\n",
    "    \"\"\"\n",
    "    Построение baseline методом concave rubberband для одного спектра\n",
    "    \"\"\"\n",
    "    # равномерно выбираем n_baseline_points\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    idx = np.linspace(0, len(x)-1, n_baseline_points, dtype=int)\n",
    "    x_sample = x[idx]\n",
    "    y_sample = y[idx]\n",
    "    \n",
    "    # ищем локальные минимумы среди этих точек\n",
    "    minima_idx = argrelextrema(y_sample, np.less)[0]\n",
    "    \n",
    "    # добавляем крайние точки, если их нет\n",
    "    if 0 not in minima_idx:\n",
    "        minima_idx = np.insert(minima_idx, 0, 0)\n",
    "    if len(y_sample)-1 not in minima_idx:\n",
    "        minima_idx = np.append(minima_idx, len(y_sample)-1)\n",
    "    \n",
    "    x_min = x_sample[minima_idx]\n",
    "    y_min = y_sample[minima_idx]\n",
    "    \n",
    "    # линейная интерполяция baseline через минимумы\n",
    "    baseline = interp1d(x_min, y_min, kind='linear', fill_value=\"extrapolate\")(x)\n",
    "    # baseline = interp1d(x_min, y_min, kind='cubic', fill_value=\"extrapolate\")(x)\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "def concave_rubberband_correction(x, y, n_baseline_points=64, iterations=1):\n",
    "    \"\"\"\n",
    "    df: DataFrame (index = x, columns = спектры)\n",
    "    Возвращает скорректированный DataFrame после concave rubberband correction\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    corrected = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        y = df[col].to_numpy()\n",
    "        y_corrected = y.copy()\n",
    "        for _ in range(iterations):\n",
    "            baseline = concave_rubberband_baseline(x, y_corrected, n_baseline_points)\n",
    "            # y_corrected = y_corrected - baseline\n",
    "            y_corrected = np.maximum(y_corrected - baseline, 0)\n",
    "        corrected[col] = y_corrected\n",
    "    \n",
    "    return pd.DataFrame(corrected, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50aa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "import os\n",
    "# import dill\n",
    "\n",
    "\n",
    "def mp_bgcorrection(func, y, lim_single=8, lim_tp=40, progressCallback=None):\n",
    "    if len(y) < 1:\n",
    "        return y.copy()\n",
    "    if y.ndim < 2:\n",
    "        return func(y)\n",
    "    if hasattr(os, 'sched_getaffinity'):\n",
    "        cpus = len(os.sched_getaffinity(os.getpid()))\n",
    "    else:\n",
    "        cpus = os.cpu_count()\n",
    "    cpus = min(cpus, len(y))\n",
    "    if cpus == 1 or len(y) <= lim_single:\n",
    "        cpus = 1\n",
    "        it = map(func, y)\n",
    "    elif len(y) <= lim_tp:\n",
    "        cpus = min(cpus, 3)\n",
    "        pool = ThreadPool(cpus)\n",
    "        it = pool.imap(func, y, chunksize=5)\n",
    "    else:\n",
    "        pool = Pool(cpus)\n",
    "        it = pool.imap(*pack_function_for_map(func, y), chunksize=10)\n",
    "\n",
    "    ret = np.empty_like(y)\n",
    "    for i in range(len(y)):\n",
    "        ret[i] = next(it)\n",
    "        if progressCallback:\n",
    "            progressCallback(i+1, len(y))\n",
    "    return ret\n",
    "\n",
    "def rubberband(x, y, progressCallback=None):\n",
    "    \"\"\"\n",
    "    Rubberband baseline correction of one or more spectra.\n",
    "    Parameters:\n",
    "    x: wavenumbers, sorted in either direction\n",
    "    y: spectrum at those wavenumbers, or multiple spectra as array of shape (spectrum, wavenumber)\n",
    "    progressCallback(int a, int b): callback function called to indicated that the processing\n",
    "        is complete to a fraction a/b.\n",
    "    Returns: baseline of the spectrum, measured at the same points\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x = np.array(y)\n",
    "\n",
    "    if x[0] > x[-1]:\n",
    "        return rubberband(x[::-1], y[...,::-1],\n",
    "                          progressCallback=progressCallback)[...,::-1]\n",
    "    def rubberband_one(yy):\n",
    "        # Find the convex hull\n",
    "        v = ConvexHull(np.column_stack((x, yy))).vertices\n",
    "        # Rotate convex hull vertices until they start from the lowest one\n",
    "        v = np.roll(v, -v.argmin())\n",
    "        # Leave only the ascending part\n",
    "        v = v[:v.argmax()+1]\n",
    "        # Create baseline using linear interpolation between vertices\n",
    "        b = np.interp(x, x[v], yy[v])\n",
    "        return b\n",
    "    return mp_bgcorrection(rubberband_one, y, lim_single=100, lim_tp=10000,\n",
    "                           progressCallback=progressCallback)\n",
    "\n",
    "def concaverubberband(x, y, iters=1, progressCallback=None):\n",
    "    \"\"\"\n",
    "    Concave rubberband baseline correction. This algorithm removes more than a\n",
    "    straight line, alternating with normal rubberband to bring negative points\n",
    "    up again. It does not converge nicely and will eat up all the data if run\n",
    "    with many iterations.\n",
    "    Parameters:\n",
    "    x: wavenumbers, sorted from low to high (todo: implement high-to-low)\n",
    "    y: spectrum at those wavenumbers\n",
    "    iters: iterations to run; note that this algorithm doesn't converge nicely\n",
    "    progressCallback(int a, int b): callback function called to indicated that the processing\n",
    "        is complete to a fraction a/b.\n",
    "    Returns: baseline of the spectrum, measured at the same points\n",
    "    \"\"\"\n",
    "    def concaverubberband_one(yy):\n",
    "        origyy = yy\n",
    "        yy = yy - rubberband(x, yy);\n",
    "        for i in range(iters):\n",
    "            F = .1 * (yy.max() - yy.min())\n",
    "            xmid = .5 * (x[-1] + x[0])\n",
    "            d2 = .25 * (x[-1] - x[0]) ** 2\n",
    "            yy += F * (x - xmid)**2 / d2\n",
    "            yy -= rubberband(x, yy);\n",
    "        return origyy - yy\n",
    "    return mp_bgcorrection(concaverubberband_one, y, lim_single=30, lim_tp=500,\n",
    "                           progressCallback=progressCallback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concave_rubberband_baseline(x, y, n_points=64, iterations=1):\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Строим нижнюю оболочку (как резинка)\n",
    "    baseline_points = np.linspace(0, len(x)-1, n_points, dtype=int)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x_sel = x[baseline_points]\n",
    "        y_sel = y[baseline_points]\n",
    "\n",
    "        # находим \"выпуклую оболочку\" для этих точек\n",
    "        hull = ConvexHull(np.column_stack([x_sel, y_sel]))\n",
    "        hull_points = np.unique(hull.vertices)\n",
    "\n",
    "        # оставляем только нижнюю часть\n",
    "        hull_points = hull_points[np.argsort(x_sel[hull_points])]\n",
    "        baseline_points = hull_points\n",
    "\n",
    "    # интерполяция базовой линии\n",
    "    baseline = np.interp(x, x_sel[baseline_points], y_sel[baseline_points])\n",
    "\n",
    "    corrected = y - baseline\n",
    "    return  corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример данных\n",
    "# x = np.linspace(0, 10, 200)\n",
    "# y = np.sin(x) + 0.1*x + np.random.normal(0, 0.1, size=200) + 5  # \"спектр\" с фоном\n",
    "\n",
    "corrected = rubberband(df_x, df_y.iloc[:, 100])\n",
    "\n",
    "\n",
    "plt.plot(df_x, df_y.iloc[:, 100], label=\"Исходный спектр\")\n",
    "# plt.plot(df_x, baseline, label=\"Baseline (rubber band)\")\n",
    "plt.plot(df_x, corrected, label=\"Корректированный\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4647f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int([1.5, 2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee72711",
   "metadata": {},
   "source": [
    "# IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ir\\2025_09_24\\clean_pmma.dpt', delimiter='\\t', header=None)\n",
    "\n",
    "df2_x = df2.iloc[:, 0].copy()\n",
    "df2_y = df2.iloc[:, 1:].copy()\n",
    "\n",
    "df2_x = df2_x.iloc[::-1].copy()\n",
    "df2_y = df2_y.iloc[::-1].copy()\n",
    "\n",
    "df2_x.reset_index(drop=True, inplace=True)\n",
    "df2_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df2_x_copy = df2_x.copy()\n",
    "df2_y_copy = df2_y.copy()\n",
    "\n",
    "x_begin = 700\n",
    "x_end = 1800\n",
    "\n",
    "x_begin = df2_x_copy[df2_x_copy>=x_begin].index[0]\n",
    "x_end = df2_x_copy[df2_x_copy>=x_end].index[0]\n",
    "\n",
    "df2_x = df2_x_copy.iloc[x_begin:x_end].copy()\n",
    "df2_y = df2_y_copy.iloc[x_begin:x_end, :].copy()\n",
    "\n",
    "df2_x.reset_index(drop=True, inplace=True)\n",
    "df2_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "baseline_fitter = Baseline(df2_x, check_finite=False)\n",
    "\n",
    "df_bg = pd.DataFrame()\n",
    "df_f = pd.DataFrame()\n",
    "for i in range(df2_y.shape[1]):\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.asls(df_y.iloc[:, i], lam=1e7, p=0.007)[0]\n",
    "    df_bg[df2_y.columns[i]] = baseline_fitter.rubberband(df2_y.iloc[:, i], smooth_half_window=15)[0]\n",
    "    df_f[df2_y.columns[i]] = df2_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "df_f[df_f<0] = 0\n",
    "\n",
    "\n",
    "df2_mean = df_f.mean(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))  # 1 строкa, 2 столбца\n",
    "\n",
    "axes[0].plot(df2_x, df_f.iloc[:, :], color=colors[0])\n",
    "axes[0].set_title(\"all\")\n",
    "axes[1].plot(df2_x, df2_mean, color=colors[1])\n",
    "axes[1].set_title(\"mean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_path = r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ir\\pmma'\n",
    "df3_y = pd.DataFrame()\n",
    "for file in sorted(os.listdir(subfolder_path), key=numericalSort):\n",
    "    file_path = os.path.join(subfolder_path, file)\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "\n",
    "    df3_y[file[:-4]] = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "df3_x = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 0]\n",
    "\n",
    "df3_x = df3_x.iloc[::-1].copy()\n",
    "df3_y = df3_y.iloc[::-1].copy()\n",
    "\n",
    "df3_x.reset_index(drop=True, inplace=True)\n",
    "df3_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df3_x_copy = df3_x.copy()\n",
    "df3_y_copy = df3_y.copy()\n",
    "\n",
    "x_begin = 700\n",
    "x_end = 1800\n",
    "\n",
    "x_begin = df3_x_copy[df3_x_copy>=x_begin].index[0]\n",
    "x_end = df3_x_copy[df3_x_copy>=x_end].index[0]\n",
    "\n",
    "df3_x = df3_x_copy.iloc[x_begin:x_end].copy()\n",
    "df3_y = df3_y_copy.iloc[x_begin:x_end, :].copy()\n",
    "\n",
    "df3_x.reset_index(drop=True, inplace=True)\n",
    "df3_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df4 = pd.concat((df2_mean, df3_y), axis=1)\n",
    "df4 = df4.rename(columns={0: 'clean_pmma', 'pmma_10_2mw': 'pmma_10mw'})\n",
    "df4.drop(columns='pmma_10_1mw', inplace=True)\n",
    "\n",
    "df4_cols = list(df4.columns)\n",
    "df4 = df4[df4_cols[1:] + df4_cols[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e513752",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(df4.shape[1]):\n",
    "    plt.plot(df3_x, df4.iloc[:, i], c=colors[i], label=df4.columns[i], linewidth=2)\n",
    "\n",
    "    # plt.text(1650, df_means_smooth.iloc[660, i]+(5-i)*0.5, classes[i], c='k' )\n",
    "\n",
    "plt.text(1100, 0.3 * 1.05, 1, c='k', fontsize=20)\n",
    "plt.text(1100, 0.3 * 0.98, 2, c='k', fontsize=20)\n",
    "plt.text(1100, 0.3 * 0.65, 3, c='k', fontsize=20)\n",
    "plt.text(1090, 0.3 * 0.4, 4, c='k', fontsize=20)\n",
    "plt.text(1110, 0.3 * 0.1, 5, c='k', fontsize=20)\n",
    "plt.text(1110, 0.3 * -0.03, 6, c='k', fontsize=20)\n",
    "plt.text(1060, 0.3 * 0.06, 7, c='k', fontsize=20)\n",
    "plt.text(970, 0.3 * -0.03, 8, c='k', fontsize=20)\n",
    "\n",
    "# plt.xlim((700, 1800))\n",
    "# ax.set_xticks(np.arange(800, 4000, 200))\n",
    "# plt.title('пмма, ик')\n",
    "# ax.set_yticklabels([])\n",
    "plt.xlabel('$Волновое\\ число, см^{-1}$', fontsize=20)\n",
    "plt.ylabel('$Интенсивность,\\ усл.\\ ед.$', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4220b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i in range(df4.shape[1]):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df3_x,\n",
    "        y=df4.iloc[:, i],  # смещение\n",
    "        mode=\"lines\",\n",
    "        name=classes[i],\n",
    "        line=dict(color=colors[i])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    title=\"Mean spectra by class\",\n",
    "    xaxis_title=\"Wavenumber, cm⁻¹\",\n",
    "    yaxis_title=\"a.u.\",\n",
    "    legend_title=\"Классы\"\n",
    ")\n",
    "\n",
    "# Ограничения оси X (как у тебя в комментарии)\n",
    "# fig.update_xaxes(range=[700, 1800], dtick=200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder_path = r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\ir_2\\pmma'\n",
    "df_y = pd.DataFrame()\n",
    "for file in sorted(os.listdir(subfolder_path), key=numericalSort):\n",
    "    file_path = os.path.join(subfolder_path, file)\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "\n",
    "    df_y[file[:-4]] = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "df_x = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 0]\n",
    "\n",
    "df_x = df_x.iloc[::-1].copy()\n",
    "df_y = df_y.iloc[::-1].copy()\n",
    "\n",
    "df_x.reset_index(drop=True, inplace=True)\n",
    "df_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_x_copy = df_x.copy()\n",
    "df_y_copy = df_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_begin = 700\n",
    "x_end = 2000\n",
    "\n",
    "x_begin = df_x_copy[df_x_copy>=x_begin].index[0]\n",
    "x_end = df_x_copy[df_x_copy>=x_end].index[0]\n",
    "\n",
    "df_x = df_x_copy.iloc[x_begin:x_end].copy()\n",
    "df_y = df_y_copy.iloc[x_begin:x_end, :].copy()\n",
    "\n",
    "df_x.reset_index(drop=True, inplace=True)\n",
    "df_y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "df_bg = pd.DataFrame()\n",
    "df_f = pd.DataFrame()\n",
    "for i in range(df_y.shape[1]):\n",
    "    df_bg[samle_names[i]] = baseline_fitter.asls(df_y.iloc[:, i], lam=1e5, p=0.01)[0]\n",
    "    # df_bg[df_y.columns[i]] = baseline_fitter.rubberband(df_y.iloc[:, i], smooth_half_window=15)[0]\n",
    "    df_f[df_y.columns[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "    # df_bg[df2_y.columns[i]] = concave_rubberband_baseline(df2_x, df2_y.iloc[:, i])\n",
    "    # df_f[df2_y.columns[i]] = df2_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    # df_f.iloc[:, i] = df_f.iloc[:, i] / max(df_f.iloc[:, i])\n",
    "df_f[df_f<0] = 0\n",
    "\n",
    "# for i in range(df_f.shape[1]):\n",
    "#     df_smooth[df_names[i]] = savgol_filter(df_y.iloc[:, i], 25, 4)\n",
    "#     df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "for i in range(df_f.shape[1]):\n",
    "    df_f.iloc[:, i] = df_f.iloc[:, i] / max(df_f.iloc[:, i])\n",
    "\n",
    "df_mean = df_f.mean(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))  # 1 строкa, 2 столбца\n",
    "\n",
    "\n",
    "axes[0].plot(df_x, df_f.iloc[:, :], color=colors[0])\n",
    "axes[0].set_title(\"all\")\n",
    "\n",
    "axes[1].plot(df_x, df_mean, color=colors[1])\n",
    "axes[1].set_title(\"mean\")\n",
    "\n",
    "\n",
    "# plt.plot(df2_x, df_f.iloc[:, :])\n",
    "# plt.xlim((800, 820))\n",
    "# plt.ylim((0.9, 1.1))\n",
    "# plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "# plt.ylabel('$a.u.$')\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f78706",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pmma = df_f.iloc[:, -1]\n",
    "cd_pmma = df_f.iloc[:, :-3]\n",
    "cd_diff = pd.DataFrame()\n",
    "\n",
    "for i in cd_pmma.columns:\n",
    "    cd_diff.loc[:, i] = clean_pmma - cd_pmma.loc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3025a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_x, cd_diff.mean(axis=1))\n",
    "# plt.xlim((800, 820))\n",
    "# plt.ylim((0.9, 1.1))\n",
    "plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "plt.ylabel('$a.u.$')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_1 = pca.fit_transform(df_f.iloc[:, :].T) #1195\n",
    "\n",
    "pc_1 = 1\n",
    "pc_2 = 2\n",
    "\n",
    "scatter = plt.scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1] , s=100, edgecolors='k')\n",
    "# plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "# confidence_ellipse(pca_1[0+10*i:10+10*i, pc_1-1], pca_1[0+10*i:10+10*i, pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], alpha=0.2)\n",
    "\n",
    "plt.xlabel(f'${pc_1}\\ pc:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%')\n",
    "plt.ylabel(f'${pc_2}\\ pc:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%')\n",
    "plt.title('$PCA$')\n",
    "\n",
    "# legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "#                           markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "#                    for cls, color in colors_n.items()]\n",
    "\n",
    "# plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra(df4, df3_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee388fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df3_x, check_finite=False)\n",
    "\n",
    "df_bg = pd.DataFrame()\n",
    "df_f = pd.DataFrame()\n",
    "for i in range(df3_y.shape[1]):\n",
    "    # df_bg[samle_names[i]] = baseline_fitter.asls(df_y.iloc[:, i], lam=1e7, p=0.007)[0]\n",
    "    df_bg[df3_y.columns[i]] = baseline_fitter.rubberband(df3_y.iloc[:, i], smooth_half_window=15)[0]\n",
    "    df_f[df3_y.columns[i]] = df3_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "    # df_bg[df2_y.columns[i]] = concave_rubberband_baseline(df2_x, df2_y.iloc[:, i])\n",
    "    # df_f[df2_y.columns[i]] = df2_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    df_f.iloc[:, i] = df_f.iloc[:, i] / max(df_f.iloc[:, i])\n",
    "df_f[df_f<0] = 0\n",
    "\n",
    "# for i in range(df_f.shape[1]):\n",
    "#     df_smooth[df_names[i]] = savgol_filter(df_y.iloc[:, i], 25, 4)\n",
    "#     df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "# for i in range(df_f.shape[1]):\n",
    "#     df_f.iloc[:, i] = df_f.iloc[:, i] / max(df_f.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9\n",
    "\n",
    "fig = go.Figure()\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=df2_x, y=df2_mean, mode='lines', name='clean_pmma'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=df3_x, y=df_f.iloc[:, i], mode='lines', name=f'{df_f.columns[i]}'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 9], mode='lines'), secondary_y=True)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 10], mode='lines'), secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, 4] - df_f.iloc[:, 10], mode='lines'), secondary_y=False)\n",
    "# for i in range(10, 14):\n",
    "#     fig.add_trace(go.Scatter(x=df_x, y=df_f.iloc[:, i], mode='lines', line=dict(color=\"#4361ee\")), secondary_y=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=10, r=10, t=10, b=20), width=1300, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83356b62",
   "metadata": {},
   "source": [
    "# some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mw = [4, 6, 8, 10, 12, 14, 16]\n",
    "dat_1 = [i * 1e-6 for i in dat_mw]\n",
    "dat_f = [i / (2.2167 * 1e-8) for i in dat_1]\n",
    "dat_peak = [i / (260 * 1e-15) for i in dat_f]\n",
    "np.array(dat_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f74e7",
   "metadata": {},
   "source": [
    "# Fluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de657e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma_fl\\fl_data\\561'\n",
    "all_dfs = []\n",
    "for file in sorted(os.listdir(folder), key=numericalSort):\n",
    "    file_path = os.path.join(folder, file)\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "\n",
    "    # df = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "    df = pd.DataFrame()\n",
    "    if f\"{fold_name}_{folder}\" not in classes:\n",
    "            classes.append(f\"{fold_name}_{folder}\")\n",
    "    classes_n.append(f\"{fold_name}_{folder}\")\n",
    "    samle_names.append(f\"{fold_name}_{folder}_{os.path.splitext(file)[0]}\")\n",
    "    column_name = f\"{fold_name}_{folder}_{os.path.splitext(file)[0]}\"\n",
    "    # dd = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "    # dd.to_csv(rf'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\data_fl\\561\\{file}.dat', header=None, index=None, sep='\\t')\n",
    "    df[column_name] = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 1]\n",
    "    fl_x = pd.read_csv(file_path, delimiter='\\t', header=None).iloc[:, 0]\n",
    "    all_dfs.append(df)\n",
    "\n",
    "if all_dfs:\n",
    "    result = pd.concat(all_dfs, axis=1)\n",
    "else:\n",
    "    result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(result.shape[1]):\n",
    "    # plt.plot(fl_x, result.iloc[:, i] / result.iloc[:, i].max(), color=colors[i], label=f'{result.columns[i][-5:]}')\n",
    "    plt.plot(fl_x, result.iloc[:, i], color=colors[i], label=f'{result.columns[i][-5:]}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a499fcd",
   "metadata": {},
   "source": [
    "# raman r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc09b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c583a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "baselines = [\n",
    "    baseline_fitter.imodpoly,\n",
    "    baseline_fitter.penalized_poly,\n",
    "    baseline_fitter.loess,\n",
    "    baseline_fitter.quant_reg,\n",
    "    baseline_fitter.goldindec, \n",
    "    baseline_fitter.asls,\n",
    "    baseline_fitter.iasls, \n",
    "    baseline_fitter.airpls, \n",
    "    baseline_fitter.arpls,\n",
    "    baseline_fitter.drpls, \n",
    "    baseline_fitter.iarpls, \n",
    "    baseline_fitter.aspls,\n",
    "    baseline_fitter.psalsa, \n",
    "    baseline_fitter.derpsalsa,\n",
    "    baseline_fitter.brpls, \n",
    "    baseline_fitter.lsrpls,\n",
    "    baseline_fitter.mpls,\n",
    "    baseline_fitter.mor, \n",
    "    baseline_fitter.imor, \n",
    "    baseline_fitter.mormol, \n",
    "    baseline_fitter.amormol, \n",
    "    baseline_fitter.rolling_ball, \n",
    "    baseline_fitter.mwmv, \n",
    "    baseline_fitter.tophat, \n",
    "    baseline_fitter.mpspline, \n",
    "    baseline_fitter.jbcd, \n",
    "    baseline_fitter.mixture_model, \n",
    "    baseline_fitter.irsqr,\n",
    "    baseline_fitter.corner_cutting, \n",
    "    baseline_fitter.pspline_asls, \n",
    "    baseline_fitter.pspline_iasls, \n",
    "    baseline_fitter.pspline_airpls, \n",
    "    baseline_fitter.pspline_arpls, \n",
    "    baseline_fitter.pspline_drpls, \n",
    "    baseline_fitter.pspline_iarpls, \n",
    "    baseline_fitter.pspline_aspls, \n",
    "    baseline_fitter.pspline_psalsa, \n",
    "    baseline_fitter.pspline_derpsalsa, \n",
    "    baseline_fitter.pspline_mpls, \n",
    "    baseline_fitter.pspline_brpls, \n",
    "    baseline_fitter.pspline_lsrpls, \n",
    "    baseline_fitter.noise_median, \n",
    "    baseline_fitter.snip, \n",
    "    baseline_fitter.swima, \n",
    "    baseline_fitter.ipsa, \n",
    "    baseline_fitter.ria, \n",
    "    baseline_fitter.peak_filling, \n",
    "    baseline_fitter.dietrich, \n",
    "    baseline_fitter.golotvin, \n",
    "    baseline_fitter.std_distribution, \n",
    "    baseline_fitter.fastchrom, \n",
    "    baseline_fitter.cwt_br, \n",
    "    baseline_fitter.fabc, \n",
    "    baseline_fitter.rubberband, \n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter. \n",
    "]\n",
    "\n",
    "for baseline in baselines:\n",
    "    df_bg = pd.DataFrame()\n",
    "    df_f = pd.DataFrame()\n",
    "    df_norm = pd.DataFrame()\n",
    "    df_y_mod = pd.DataFrame()\n",
    "\n",
    "    for i in range(df_y.shape[1]):\n",
    "       \n",
    "        df_bg[samle_names[i]] = baseline(df_y.iloc[:, i])[0]\n",
    "        df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    df_f[df_f<0] = 0\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_norm[samle_names[i]] = (df_f.iloc[:, i] - df_f.iloc[:, i].mean()) / df_f.iloc[:, i].std()    \n",
    "\n",
    "    for i in range(df_norm.shape[1]):\n",
    "        y =  df_norm.iloc[:, i]\n",
    "        x = df_x\n",
    "        f_interp = interp1d(x, y, kind='cubic')\n",
    "        new_x = np.linspace(x.iloc[0], x.iloc[-1], 501)\n",
    "        new_y = f_interp(new_x)\n",
    "        df_y_mod[df_norm.columns[i]] = new_y\n",
    "\n",
    "    new_df_x = new_x.copy()\n",
    "    new_df_norm = df_y_mod.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4), ncols=2, nrows=1)\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    # pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "    pca_1 = pca.fit_transform((new_df_norm.iloc[:, :].T))\n",
    "    # pca_1 = pca.fit_transform(StandardScaler().fit_transform(new_df_norm.iloc[:, :].T))\n",
    "    # pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0].scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "    # plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    # values, counts = np.unique(classes_n, return_counts=True)\n",
    "\n",
    "    # order = np.argsort([classes.index(v) for v in values])\n",
    "    # values = values[order]\n",
    "    # counts = counts[order]\n",
    "\n",
    "    # n_uniq = len(values)\n",
    "    # cum_sum = np.cumsum(counts)\n",
    "    # for i in range(n_uniq):\n",
    "    #        if i == 0:\n",
    "    #               confidence_ellipse(pca_1[0:cum_sum[i], pc_1-1], pca_1[0:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "    #        elif i == 6:\n",
    "    #               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=1, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "    #        else:\n",
    "    #               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "\n",
    "\n",
    "    ax[0].set_title(f'PCA {baseline.__name__}')\n",
    "    ax[0].set_xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "    ax[0].set_ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "    # plt.xlabel(f'${pc_1}я\\ главная\\ компонента:$ {55.91}%', fontsize=17)\n",
    "    # plt.ylabel(f'${pc_2}я\\ главная\\ компонента:$ {16.38}%', fontsize=17)\n",
    "    # plt.title('$PCA,\\ раман$')\n",
    "    # ax[0].xticks(fontsize=15)\n",
    "    # ax[0].set_yticks(fontsize=15)\n",
    "\n",
    "    # legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "    #                         markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "    #                 for cls, color in colors_n.items()]\n",
    "\n",
    "    # plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "    pls_binary = PLSRegression(n_components=10)\n",
    "    # Fit and transform the data\n",
    "    X_pls = pls_binary.fit_transform(df_y_mod.T, classes_mw)[0]\n",
    "    # X_pls = pls_binary.fit_transform(StandardScaler().fit_transform(df_y_mod.T), classes_mw)[0]\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[1].scatter(X_pls[:, pc_1-1], X_pls[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "    # for i in range(10):\n",
    "    #     plt.scatter(X_pls[0+10*i:10+10*i, 1], X_pls[0+10*i:10+10*i, 2], c=colors[i], s=100, edgecolors='k')\n",
    "    #     plt.text(np.mean(X_pls[0+10*i:10+10*i, 1]), np.mean(X_pls[0+10*i:10+10*i, 2]), paper_Y[i], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    ax[1].set_xlabel('Latent Variable 1')\n",
    "    ax[1].set_ylabel('Latent Variable 2')\n",
    "    # plt.legend(labplot,loc='lower left')\n",
    "    ax[1].set_title(f'PLS {baseline.__name__}')\n",
    "    # plt.show()\n",
    "    # plt.plot(df_x, df_f.iloc[:, :])\n",
    "    \n",
    "    # plt.xlim((800, 820))\n",
    "    # plt.ylim((0.9, 1.1))\n",
    "    # plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "    # plt.ylabel('$a.u.$')\n",
    "    # plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "baselines = [\n",
    "    baseline_fitter.imodpoly,\n",
    "    baseline_fitter.penalized_poly,\n",
    "    baseline_fitter.loess,\n",
    "    baseline_fitter.quant_reg,\n",
    "    baseline_fitter.goldindec, \n",
    "    baseline_fitter.asls,\n",
    "    baseline_fitter.iasls, \n",
    "    baseline_fitter.airpls, \n",
    "    baseline_fitter.arpls,\n",
    "    baseline_fitter.drpls, \n",
    "    baseline_fitter.iarpls, \n",
    "    baseline_fitter.aspls,\n",
    "    baseline_fitter.psalsa, \n",
    "    baseline_fitter.derpsalsa,\n",
    "    baseline_fitter.brpls, \n",
    "    baseline_fitter.lsrpls,\n",
    "    baseline_fitter.mpls,\n",
    "    baseline_fitter.mor, \n",
    "    baseline_fitter.imor, \n",
    "    baseline_fitter.mormol, \n",
    "    baseline_fitter.amormol, \n",
    "    baseline_fitter.rolling_ball, \n",
    "    baseline_fitter.mwmv, \n",
    "    baseline_fitter.tophat, \n",
    "    baseline_fitter.mpspline, \n",
    "    baseline_fitter.jbcd, \n",
    "    baseline_fitter.mixture_model, \n",
    "    baseline_fitter.irsqr,\n",
    "    baseline_fitter.corner_cutting, \n",
    "    baseline_fitter.pspline_asls, \n",
    "    baseline_fitter.pspline_iasls, \n",
    "    baseline_fitter.pspline_airpls, \n",
    "    baseline_fitter.pspline_arpls, \n",
    "    baseline_fitter.pspline_drpls, \n",
    "    baseline_fitter.pspline_iarpls, \n",
    "    baseline_fitter.pspline_aspls, \n",
    "    baseline_fitter.pspline_psalsa, \n",
    "    baseline_fitter.pspline_derpsalsa, \n",
    "    baseline_fitter.pspline_mpls, \n",
    "    baseline_fitter.pspline_brpls, \n",
    "    baseline_fitter.pspline_lsrpls, \n",
    "    baseline_fitter.noise_median, \n",
    "    baseline_fitter.snip, \n",
    "    baseline_fitter.swima, \n",
    "    baseline_fitter.ipsa, \n",
    "    baseline_fitter.ria, \n",
    "    baseline_fitter.peak_filling, \n",
    "    baseline_fitter.dietrich, \n",
    "    baseline_fitter.golotvin, \n",
    "    baseline_fitter.std_distribution, \n",
    "    baseline_fitter.fastchrom, \n",
    "    baseline_fitter.cwt_br, \n",
    "    baseline_fitter.fabc, \n",
    "    baseline_fitter.rubberband, \n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter.\n",
    "    # baseline_fitter. \n",
    "]\n",
    "\n",
    "for baseline in baselines:\n",
    "    df_bg = pd.DataFrame()\n",
    "    df_f = pd.DataFrame()\n",
    "    df_norm = pd.DataFrame()\n",
    "    df_y_mod = pd.DataFrame()\n",
    "\n",
    "    for i in range(df_y.shape[1]):\n",
    "       \n",
    "        df_bg[samle_names[i]] = baseline(df_y.iloc[:, i])[0]\n",
    "        df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    df_f[df_f<0] = 0\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_norm[samle_names[i]] = (df_f.iloc[:, i] - df_f.iloc[:, i].mean()) / df_f.iloc[:, i].std()    \n",
    "\n",
    "    for i in range(df_norm.shape[1]):\n",
    "        y =  df_norm.iloc[:, i]\n",
    "        x = df_x\n",
    "        f_interp = interp1d(x, y, kind='cubic')\n",
    "        new_x = np.linspace(x.iloc[0], x.iloc[-1], 501)\n",
    "        new_y = f_interp(new_x)\n",
    "        df_y_mod[df_norm.columns[i]] = new_y\n",
    "\n",
    "    new_df_x = new_x.copy()\n",
    "    new_df_norm = df_y_mod.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4), ncols=2, nrows=1)\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    # pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "    pca_1 = pca.fit_transform((new_df_norm.iloc[:, :-11].T))\n",
    "    # pca_1 = pca.fit_transform(StandardScaler().fit_transform(new_df_norm.iloc[:, :].T))\n",
    "    # pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0].scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points[:-11] , s=100, edgecolors='k')\n",
    "    # plt.text(np.mean(pca_1[0+10*i:10+10*i, 0]), np.mean(pca_1[0+10*i:10+10*i, 1]), IR_files_names[i][3:7], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    # values, counts = np.unique(classes_n, return_counts=True)\n",
    "\n",
    "    # order = np.argsort([classes.index(v) for v in values])\n",
    "    # values = values[order]\n",
    "    # counts = counts[order]\n",
    "\n",
    "    # n_uniq = len(values)\n",
    "    # cum_sum = np.cumsum(counts)\n",
    "    # for i in range(n_uniq):\n",
    "    #        if i == 0:\n",
    "    #               confidence_ellipse(pca_1[0:cum_sum[i], pc_1-1], pca_1[0:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "    #        elif i == 6:\n",
    "    #               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=1, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "    #        else:\n",
    "    #               confidence_ellipse(pca_1[cum_sum[i-1]:cum_sum[i], pc_1-1], pca_1[cum_sum[i-1]:cum_sum[i], pc_2-1], ax, n_std=2, edgecolor=colors[i], facecolor=colors[i], center_color=colors[i], alpha=0.1, text=i+1)\n",
    "\n",
    "\n",
    "    ax[0].set_title(f'PCA {baseline.__name__}')\n",
    "    ax[0].set_xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "    ax[0].set_ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "    # plt.xlabel(f'${pc_1}я\\ главная\\ компонента:$ {55.91}%', fontsize=17)\n",
    "    # plt.ylabel(f'${pc_2}я\\ главная\\ компонента:$ {16.38}%', fontsize=17)\n",
    "    # plt.title('$PCA,\\ раман$')\n",
    "    # ax[0].xticks(fontsize=15)\n",
    "    # ax[0].set_yticks(fontsize=15)\n",
    "\n",
    "    # legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "    #                         markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "    #                 for cls, color in colors_n.items()]\n",
    "\n",
    "    # plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "\n",
    "    pls_binary = PLSRegression(n_components=10)\n",
    "    # Fit and transform the data\n",
    "    X_pls = pls_binary.fit_transform(df_y_mod.iloc[:, :-11].T, classes_mw[:-11])[0]\n",
    "    # X_pls = pls_binary.fit_transform(StandardScaler().fit_transform(df_y_mod.T), classes_mw)[0]\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[1].scatter(X_pls[:, pc_1-1], X_pls[:, pc_2-1], c=colors_for_points[:-11] , s=100, edgecolors='k')\n",
    "    # for i in range(10):\n",
    "    #     plt.scatter(X_pls[0+10*i:10+10*i, 1], X_pls[0+10*i:10+10*i, 2], c=colors[i], s=100, edgecolors='k')\n",
    "    #     plt.text(np.mean(X_pls[0+10*i:10+10*i, 1]), np.mean(X_pls[0+10*i:10+10*i, 2]), paper_Y[i], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    ax[1].set_xlabel('Latent Variable 1')\n",
    "    ax[1].set_ylabel('Latent Variable 2')\n",
    "    # plt.legend(labplot,loc='lower left')\n",
    "    ax[1].set_title(f'PLS {baseline.__name__}')\n",
    "    # plt.show()\n",
    "    # plt.plot(df_x, df_f.iloc[:, :])\n",
    "    \n",
    "    # plt.xlim((800, 820))\n",
    "    # plt.ylim((0.9, 1.1))\n",
    "    # plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "    # plt.ylabel('$a.u.$')\n",
    "    # plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d73fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "# baselines = [\n",
    "#     baseline_fitter.imodpoly,\n",
    "#     baseline_fitter.penalized_poly,\n",
    "#     baseline_fitter.loess,\n",
    "#     baseline_fitter.quant_reg,\n",
    "#     baseline_fitter.goldindec, \n",
    "#     baseline_fitter.asls,\n",
    "#     baseline_fitter.iasls, \n",
    "#     baseline_fitter.airpls, \n",
    "#     baseline_fitter.arpls,\n",
    "#     baseline_fitter.drpls, \n",
    "#     baseline_fitter.iarpls, \n",
    "#     baseline_fitter.aspls,\n",
    "#     baseline_fitter.psalsa, \n",
    "#     baseline_fitter.derpsalsa,\n",
    "#     baseline_fitter.brpls, \n",
    "#     baseline_fitter.lsrpls,\n",
    "#     baseline_fitter.mpls,\n",
    "#     baseline_fitter.mor, \n",
    "#     baseline_fitter.imor, \n",
    "#     baseline_fitter.mormol, \n",
    "#     baseline_fitter.amormol, \n",
    "#     baseline_fitter.rolling_ball, \n",
    "#     baseline_fitter.mwmv, \n",
    "#     baseline_fitter.tophat, \n",
    "#     baseline_fitter.mpspline, \n",
    "#     baseline_fitter.jbcd, \n",
    "#     baseline_fitter.mixture_model, \n",
    "#     baseline_fitter.irsqr,\n",
    "#     baseline_fitter.corner_cutting, \n",
    "#     baseline_fitter.pspline_asls, \n",
    "#     baseline_fitter.pspline_iasls, \n",
    "#     baseline_fitter.pspline_airpls, \n",
    "#     baseline_fitter.pspline_arpls, \n",
    "#     baseline_fitter.pspline_drpls, \n",
    "#     baseline_fitter.pspline_iarpls, \n",
    "#     baseline_fitter.pspline_aspls, \n",
    "#     baseline_fitter.pspline_psalsa, \n",
    "#     baseline_fitter.pspline_derpsalsa, \n",
    "#     baseline_fitter.pspline_mpls, \n",
    "#     baseline_fitter.pspline_brpls, \n",
    "#     baseline_fitter.pspline_lsrpls, \n",
    "#     baseline_fitter.noise_median, \n",
    "#     baseline_fitter.snip, \n",
    "#     baseline_fitter.swima, \n",
    "#     baseline_fitter.ipsa, \n",
    "#     baseline_fitter.ria, \n",
    "#     baseline_fitter.peak_filling, \n",
    "#     baseline_fitter.dietrich, \n",
    "#     baseline_fitter.golotvin, \n",
    "#     baseline_fitter.std_distribution, \n",
    "#     baseline_fitter.fastchrom, \n",
    "#     baseline_fitter.cwt_br, \n",
    "#     baseline_fitter.fabc, \n",
    "#     baseline_fitter.rubberband, \n",
    "# ]\n",
    "# lamds = [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,30,40,50,100,1e3,1e4,1e5,1e6,1e7,1e8,1e9,1e10,1e11,1e12]\n",
    "# lamds = [100,1e3,1e4,1e5,1e6,1e7,1e8,1e9,1e10,1e11,1e12]\n",
    "hw = [100]\n",
    "for la in hw:\n",
    "    df_bg = pd.DataFrame()\n",
    "    df_f = pd.DataFrame()\n",
    "    df_norm = pd.DataFrame()\n",
    "    df_y_mod = pd.DataFrame()\n",
    "\n",
    "    for i in range(df_y.shape[1]):\n",
    "       \n",
    "        # df_bg[samle_names[i]] = baseline_fitter.mor(df_y.iloc[:, i], lam=la, diff_order=2)[0]\n",
    "        df_bg[samle_names[i]] = baseline_fitter.mor(df_y.iloc[:, i], half_window=None)[0]\n",
    "        df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    df_f[df_f<0] = 0\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_norm[samle_names[i]] = (df_f.iloc[:, i] - df_f.iloc[:, i].mean()) / df_f.iloc[:, i].std()    \n",
    "\n",
    "    for i in range(df_norm.shape[1]):\n",
    "        y =  df_norm.iloc[:, i]\n",
    "        x = df_x\n",
    "        f_interp = interp1d(x, y, kind='cubic')\n",
    "        new_x = np.linspace(x.iloc[0], x.iloc[-1], 501)\n",
    "        new_y = f_interp(new_x)\n",
    "        df_y_mod[df_norm.columns[i]] = new_y\n",
    "\n",
    "    new_df_x = new_x.copy()\n",
    "    new_df_norm = df_y_mod.copy()\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(12,6), nrows=2, ncols=2)\n",
    "    fig, ax = plt.subplots(figsize=(18,10), nrows=2, ncols=2)\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    # pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "    # pca_1 = pca.fit_transform((new_df_norm.iloc[:, :].T))\n",
    "    pca_1 = pca.fit_transform(StandardScaler().fit_transform(new_df_norm.iloc[:, :].T))\n",
    "    # pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :].T))\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0, 0].scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "\n",
    "    ax[0, 0].set_title(f'{la}')\n",
    "    ax[0, 0].set_xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "    ax[0, 0].set_ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "    # plt.xticks(fontsize=15)\n",
    "    # plt.yticks(fontsize=15)\n",
    "\n",
    "    # legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "    #                         markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "    #                 for cls, color in colors_n.items()]\n",
    "\n",
    "    # plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "    ax[1, 0].scatter(pca.components_[pc_1-1, :], pca.components_[pc_2-1, :])\n",
    "    for i, label in enumerate(new_df_x):\n",
    "        ax[1, 0].text(pca.components_[pc_1-1, i], pca.components_[pc_2-1, i], f'{label:.0f}', fontsize=3)\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "    # ax[0, 1].plot(new_df_x, new_df_norm.iloc[:, :])\n",
    "\n",
    "    pls_binary = PLSRegression(n_components=10)\n",
    "    # Fit and transform the data\n",
    "    # X_pls = pls_binary.fit_transform(df_y_mod.T, classes_mw)[0]\n",
    "    X_pls = pls_binary.fit_transform(StandardScaler().fit_transform(df_y_mod.T), classes_mw)[0]\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0, 1].scatter(X_pls[:, pc_1-1], X_pls[:, pc_2-1], c=colors_for_points , s=100, edgecolors='k')\n",
    "    # for i in range(10):\n",
    "    #     plt.scatter(X_pls[0+10*i:10+10*i, 1], X_pls[0+10*i:10+10*i, 2], c=colors[i], s=100, edgecolors='k')\n",
    "    #     plt.text(np.mean(X_pls[0+10*i:10+10*i, 1]), np.mean(X_pls[0+10*i:10+10*i, 2]), paper_Y[i], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    ax[0, 1].set_xlabel('Latent Variable 1')\n",
    "    ax[0, 1].set_ylabel('Latent Variable 2')\n",
    "    # plt.legend(labplot,loc='lower left')\n",
    "    ax[0, 1].set_title(f'PLS {baseline.__name__}')\n",
    "\n",
    "    ax[1, 1].scatter(pls_binary.x_loadings_[:, pc_1-1], pls_binary.x_loadings_[:, pc_2-1])\n",
    "    for i, label in enumerate(new_df_x):\n",
    "        ax[1, 1].text(pls_binary.x_loadings_[i, pc_1-1], pls_binary.x_loadings_[i, pc_2-1], f'{label:.0f}', fontsize=3)\n",
    "    \n",
    "    # plt.xlim((800, 820))\n",
    "    # plt.ylim((0.9, 1.1))\n",
    "    # plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "    # plt.ylabel('$a.u.$')\n",
    "    # plt.grid()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c51184",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fitter = Baseline(df_x, check_finite=False)\n",
    "\n",
    "# baselines = [\n",
    "#     baseline_fitter.imodpoly,\n",
    "#     baseline_fitter.penalized_poly,\n",
    "#     baseline_fitter.loess,\n",
    "#     baseline_fitter.quant_reg,\n",
    "#     baseline_fitter.goldindec, \n",
    "#     baseline_fitter.asls,\n",
    "#     baseline_fitter.iasls, \n",
    "#     baseline_fitter.airpls, \n",
    "#     baseline_fitter.arpls,\n",
    "#     baseline_fitter.drpls, \n",
    "#     baseline_fitter.iarpls, \n",
    "#     baseline_fitter.aspls,\n",
    "#     baseline_fitter.psalsa, \n",
    "#     baseline_fitter.derpsalsa,\n",
    "#     baseline_fitter.brpls, \n",
    "#     baseline_fitter.lsrpls,\n",
    "#     baseline_fitter.mpls,\n",
    "#     baseline_fitter.mor, \n",
    "#     baseline_fitter.imor, \n",
    "#     baseline_fitter.mormol, \n",
    "#     baseline_fitter.amormol, \n",
    "#     baseline_fitter.rolling_ball, \n",
    "#     baseline_fitter.mwmv, \n",
    "#     baseline_fitter.tophat, \n",
    "#     baseline_fitter.mpspline, \n",
    "#     baseline_fitter.jbcd, \n",
    "#     baseline_fitter.mixture_model, \n",
    "#     baseline_fitter.irsqr,\n",
    "#     baseline_fitter.corner_cutting, \n",
    "#     baseline_fitter.pspline_asls, \n",
    "#     baseline_fitter.pspline_iasls, \n",
    "#     baseline_fitter.pspline_airpls, \n",
    "#     baseline_fitter.pspline_arpls, \n",
    "#     baseline_fitter.pspline_drpls, \n",
    "#     baseline_fitter.pspline_iarpls, \n",
    "#     baseline_fitter.pspline_aspls, \n",
    "#     baseline_fitter.pspline_psalsa, \n",
    "#     baseline_fitter.pspline_derpsalsa, \n",
    "#     baseline_fitter.pspline_mpls, \n",
    "#     baseline_fitter.pspline_brpls, \n",
    "#     baseline_fitter.pspline_lsrpls, \n",
    "#     baseline_fitter.noise_median, \n",
    "#     baseline_fitter.snip, \n",
    "#     baseline_fitter.swima, \n",
    "#     baseline_fitter.ipsa, \n",
    "#     baseline_fitter.ria, \n",
    "#     baseline_fitter.peak_filling, \n",
    "#     baseline_fitter.dietrich, \n",
    "#     baseline_fitter.golotvin, \n",
    "#     baseline_fitter.std_distribution, \n",
    "#     baseline_fitter.fastchrom, \n",
    "#     baseline_fitter.cwt_br, \n",
    "#     baseline_fitter.fabc, \n",
    "#     baseline_fitter.rubberband, \n",
    "# ]\n",
    "# lamds = [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,30,40,50,100,1e3,1e4,1e5,1e6,1e7,1e8,1e9,1e10,1e11,1e12]\n",
    "# lamds = [100,1e3,1e4,1e5,1e6,1e7,1e8,1e9,1e10,1e11,1e12]\n",
    "hw = [100]\n",
    "for la in hw:\n",
    "    df_bg = pd.DataFrame()\n",
    "    df_f = pd.DataFrame()\n",
    "    df_norm = pd.DataFrame()\n",
    "    df_y_mod = pd.DataFrame()\n",
    "\n",
    "    for i in range(df_y.shape[1]):\n",
    "       \n",
    "        # df_bg[samle_names[i]] = baseline_fitter.mor(df_y.iloc[:, i], lam=la, diff_order=2)[0]\n",
    "        df_bg[samle_names[i]] = baseline_fitter.mor(df_y.iloc[:, i], half_window=None)[0]\n",
    "        df_f[samle_names[i]] = df_y.iloc[:, i] - df_bg.iloc[:, i]\n",
    "\n",
    "    df_f[df_f<0] = 0\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_f.iloc[:, i] = gaussian_filter1d(df_f.iloc[:, i], 10)\n",
    "\n",
    "    for i in range(df_f.shape[1]):\n",
    "        df_norm[samle_names[i]] = (df_f.iloc[:, i] - df_f.iloc[:, i].mean()) / df_f.iloc[:, i].std()    \n",
    "\n",
    "    for i in range(df_norm.shape[1]):\n",
    "        y =  df_norm.iloc[:, i]\n",
    "        x = df_x\n",
    "        f_interp = interp1d(x, y, kind='cubic')\n",
    "        new_x = np.linspace(x.iloc[0], x.iloc[-1], 501)\n",
    "        new_y = f_interp(new_x)\n",
    "        df_y_mod[df_norm.columns[i]] = new_y\n",
    "\n",
    "    new_df_x = new_x.copy()\n",
    "    new_df_norm = df_y_mod.copy()\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(12,6), nrows=2, ncols=2)\n",
    "    fig, ax = plt.subplots(figsize=(18,10), nrows=2, ncols=2)\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    # pca_1 = pca.fit_transform(df_norm.iloc[:, :].T) #1195\n",
    "    # pca_1 = pca.fit_transform((new_df_norm.iloc[:, :-11].T))\n",
    "    pca_1 = pca.fit_transform(StandardScaler().fit_transform(new_df_norm.iloc[:, :-11].T))\n",
    "    # pca_1 = pca.fit_transform(MinMaxScaler().fit_transform(df_y_mod.iloc[:, :-11].T))\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0, 0].scatter(pca_1[:, pc_1-1], pca_1[:, pc_2-1], c=colors_for_points[:-11] , s=100, edgecolors='k')\n",
    "\n",
    "    ax[0, 0].set_title(f'{la}')\n",
    "    ax[0, 0].set_xlabel(f'${pc_1}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_1-1]*100:.2f}%', fontsize=15)\n",
    "    ax[0, 0].set_ylabel(f'${pc_2}\\ главная\\ компонента:$ {pca.explained_variance_ratio_[pc_2-1]*100:.2f}%', fontsize=15)\n",
    "    # plt.xticks(fontsize=15)\n",
    "    # plt.yticks(fontsize=15)\n",
    "\n",
    "    # legend_elements = [Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "    #                         markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "    #                 for cls, color in colors_n.items()]\n",
    "\n",
    "    # plt.legend(handles=legend_elements, title=\"Классы\")\n",
    "    ax[1, 0].scatter(pca.components_[pc_1-1, :], pca.components_[pc_2-1, :])\n",
    "    for i, label in enumerate(new_df_x):\n",
    "        ax[1, 0].text(pca.components_[pc_1-1, i], pca.components_[pc_2-1, i], f'{label:.0f}', fontsize=3)\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "    # ax[0, 1].plot(new_df_x, new_df_norm.iloc[:, :])\n",
    "\n",
    "    pls_binary = PLSRegression(n_components=10)\n",
    "    # Fit and transform the data\n",
    "    # X_pls = pls_binary.fit_transform(df_y_mod.T, classes_mw)[0]\n",
    "    X_pls = pls_binary.fit_transform(StandardScaler().fit_transform(df_y_mod.iloc[:, :-11].T), classes_mw[:-11])[0]\n",
    "\n",
    "    pc_1 = 1\n",
    "    pc_2 = 2\n",
    "\n",
    "    ax[0, 1].scatter(X_pls[:, pc_1-1], X_pls[:, pc_2-1], c=colors_for_points[:-11] , s=100, edgecolors='k')\n",
    "    # for i in range(10):\n",
    "    #     plt.scatter(X_pls[0+10*i:10+10*i, 1], X_pls[0+10*i:10+10*i, 2], c=colors[i], s=100, edgecolors='k')\n",
    "    #     plt.text(np.mean(X_pls[0+10*i:10+10*i, 1]), np.mean(X_pls[0+10*i:10+10*i, 2]), paper_Y[i], bbox=dict(facecolor='none', edgecolor=colors[i], boxstyle='round'))\n",
    "\n",
    "    ax[0, 1].set_xlabel('Latent Variable 1')\n",
    "    ax[0, 1].set_ylabel('Latent Variable 2')\n",
    "    # plt.legend(labplot,loc='lower left')\n",
    "    ax[0, 1].set_title(f'PLS {baseline.__name__}')\n",
    "\n",
    "    ax[1, 1].scatter(pls_binary.x_loadings_[:, pc_1-1], pls_binary.x_loadings_[:, pc_2-1])\n",
    "    for i, label in enumerate(new_df_x):\n",
    "        ax[1, 1].text(pls_binary.x_loadings_[i, pc_1-1], pls_binary.x_loadings_[i, pc_2-1], f'{label:.0f}', fontsize=3)\n",
    "    \n",
    "    # plt.xlim((800, 820))\n",
    "    # plt.ylim((0.9, 1.1))\n",
    "    # plt.xlabel('$wavenumber, cm^{-1}$')\n",
    "    # plt.ylabel('$a.u.$')\n",
    "    # plt.grid()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3775234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        r = csv.reader(f, delimiter=';')\n",
    "        header = next(r)\n",
    "        feature_names = header[2:]\n",
    "        classes = []\n",
    "        names = []\n",
    "        X = []\n",
    "        for row in r:\n",
    "            classes.append(row[0])\n",
    "            names.append(row[1])\n",
    "            X.append([float(v) for v in row[2:]])\n",
    "    return feature_names, classes, names, X\n",
    "\n",
    "\n",
    "def copy_matrix(A):\n",
    "    return [row[:] for row in A]\n",
    "\n",
    "\n",
    "def transpose(A):\n",
    "    return list(map(list, zip(*A)))\n",
    "\n",
    "\n",
    "def matmul(A, B):\n",
    "    n, m, p = len(A), len(A[0]), len(B[0])\n",
    "    out = [[0.0] * p for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        Ai = A[i]\n",
    "        Oi = out[i]\n",
    "        for k in range(m):\n",
    "            a = Ai[k]\n",
    "            Bk = B[k]\n",
    "            for j in range(p):\n",
    "                Oi[j] += a * Bk[j]\n",
    "    return out\n",
    "\n",
    "\n",
    "def matvec(A, x):\n",
    "    out = [0.0] * len(A)\n",
    "    for i, row in enumerate(A):\n",
    "        s = 0.0\n",
    "        for j, v in enumerate(row):\n",
    "            s += v * x[j]\n",
    "        out[i] = s\n",
    "    return out\n",
    "\n",
    "\n",
    "def dot(a, b):\n",
    "    return sum(x * y for x, y in zip(a, b))\n",
    "\n",
    "\n",
    "def norm(v):\n",
    "    return math.sqrt(dot(v, v))\n",
    "\n",
    "\n",
    "def center_scale(X):\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    means = [0.0] * p\n",
    "    for row in X:\n",
    "        for j, v in enumerate(row):\n",
    "            means[j] += v\n",
    "    means = [m / n for m in means]\n",
    "\n",
    "    stds = [0.0] * p\n",
    "    for row in X:\n",
    "        for j, v in enumerate(row):\n",
    "            d = v - means[j]\n",
    "            stds[j] += d * d\n",
    "    stds = [math.sqrt(s / (n - 1)) if s > 0 else 1.0 for s in stds]\n",
    "\n",
    "    Xs = [[(row[j] - means[j]) / stds[j] for j in range(p)] for row in X]\n",
    "    return Xs, means, stds\n",
    "\n",
    "\n",
    "def snv(X):\n",
    "    out = []\n",
    "    for row in X:\n",
    "        m = sum(row) / len(row)\n",
    "        var = sum((v - m) ** 2 for v in row) / max(1, (len(row) - 1))\n",
    "        s = math.sqrt(var) if var > 0 else 1.0\n",
    "        out.append([(v - m) / s for v in row])\n",
    "    return out\n",
    "\n",
    "\n",
    "def gram_matrix(X):\n",
    "    n = len(X)\n",
    "    G = [[0.0] * n for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        G[i][i] = dot(X[i], X[i])\n",
    "        for j in range(i + 1, n):\n",
    "            v = dot(X[i], X[j])\n",
    "            G[i][j] = v\n",
    "            G[j][i] = v\n",
    "    return G\n",
    "\n",
    "\n",
    "def power_eigen_symmetric(A, k=2, max_iter=300, tol=1e-9):\n",
    "    n = len(A)\n",
    "    vectors = []\n",
    "    values = []\n",
    "    for comp in range(k):\n",
    "        x = [0.0] * n\n",
    "        x[comp % n] = 1.0\n",
    "        for _ in range(max_iter):\n",
    "            y = matvec(A, x)\n",
    "            for q in vectors:\n",
    "                proj = dot(y, q)\n",
    "                for i in range(n):\n",
    "                    y[i] -= proj * q[i]\n",
    "            ny = norm(y)\n",
    "            if ny == 0:\n",
    "                break\n",
    "            y = [v / ny for v in y]\n",
    "            diff = math.sqrt(sum((y[i] - x[i]) ** 2 for i in range(n)))\n",
    "            x = y\n",
    "            if diff < tol:\n",
    "                break\n",
    "        Ax = matvec(A, x)\n",
    "        val = dot(x, Ax)\n",
    "        vectors.append(x)\n",
    "        values.append(val)\n",
    "    return values, vectors\n",
    "\n",
    "\n",
    "def pca_scores(X, n_components=2):\n",
    "    G = gram_matrix(X)\n",
    "    vals, vecs = power_eigen_symmetric(G, k=n_components)\n",
    "    scores = [[0.0] * n_components for _ in range(len(X))]\n",
    "    for c in range(n_components):\n",
    "        scale = math.sqrt(max(vals[c], 0.0))\n",
    "        for i in range(len(X)):\n",
    "            scores[i][c] = vecs[c][i] * scale\n",
    "    total_var = sum(G[i][i] for i in range(len(G)))\n",
    "    explained = [max(v, 0.0) / total_var if total_var > 0 else 0.0 for v in vals]\n",
    "    return scores, explained\n",
    "\n",
    "\n",
    "def one_hot(labels):\n",
    "    uniq = sorted(set(labels), key=lambda x: float(x))\n",
    "    idx = {c: i for i, c in enumerate(uniq)}\n",
    "    Y = []\n",
    "    for c in labels:\n",
    "        row = [0.0] * len(uniq)\n",
    "        row[idx[c]] = 1.0\n",
    "        Y.append(row)\n",
    "    return Y, uniq\n",
    "\n",
    "\n",
    "def matrix_inverse(A):\n",
    "    n = len(A)\n",
    "    M = [row[:] + [1.0 if i == j else 0.0 for j in range(n)] for i, row in enumerate(A)]\n",
    "    for col in range(n):\n",
    "        pivot = max(range(col, n), key=lambda r: abs(M[r][col]))\n",
    "        if abs(M[pivot][col]) < 1e-12:\n",
    "            raise ValueError('Singular matrix')\n",
    "        M[col], M[pivot] = M[pivot], M[col]\n",
    "        piv = M[col][col]\n",
    "        for j in range(2 * n):\n",
    "            M[col][j] /= piv\n",
    "        for i in range(n):\n",
    "            if i == col:\n",
    "                continue\n",
    "            factor = M[i][col]\n",
    "            for j in range(2 * n):\n",
    "                M[i][j] -= factor * M[col][j]\n",
    "    return [row[n:] for row in M]\n",
    "\n",
    "\n",
    "def pls_nipals(X, Y, n_components=2, max_iter=200, tol=1e-8):\n",
    "    Xh = copy_matrix(X)\n",
    "    Yh = copy_matrix(Y)\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    q = len(Y[0])\n",
    "\n",
    "    W = [[0.0] * n_components for _ in range(p)]\n",
    "    P = [[0.0] * n_components for _ in range(p)]\n",
    "    Q = [[0.0] * n_components for _ in range(q)]\n",
    "    T = [[0.0] * n_components for _ in range(n)]\n",
    "\n",
    "    for a in range(n_components):\n",
    "        u = [row[0] for row in Yh]\n",
    "        for _ in range(max_iter):\n",
    "            w = [0.0] * p\n",
    "            for j in range(p):\n",
    "                s = 0.0\n",
    "                for i in range(n):\n",
    "                    s += Xh[i][j] * u[i]\n",
    "                w[j] = s\n",
    "            nw = norm(w)\n",
    "            if nw == 0:\n",
    "                break\n",
    "            w = [v / nw for v in w]\n",
    "\n",
    "            t = [dot(row, w) for row in Xh]\n",
    "            nt = norm(t)\n",
    "            if nt == 0:\n",
    "                break\n",
    "\n",
    "            c = [0.0] * q\n",
    "            for j in range(q):\n",
    "                s = 0.0\n",
    "                for i in range(n):\n",
    "                    s += Yh[i][j] * t[i]\n",
    "                c[j] = s\n",
    "            nc = norm(c)\n",
    "            if nc == 0:\n",
    "                break\n",
    "            c = [v / nc for v in c]\n",
    "\n",
    "            u_new = [dot(row, c) for row in Yh]\n",
    "            if norm([u_new[i] - u[i] for i in range(n)]) < tol:\n",
    "                u = u_new\n",
    "                break\n",
    "            u = u_new\n",
    "\n",
    "        denom = dot(t, t) if dot(t, t) != 0 else 1.0\n",
    "        p_vec = [sum(Xh[i][j] * t[i] for i in range(n)) / denom for j in range(p)]\n",
    "        q_vec = [sum(Yh[i][j] * t[i] for i in range(n)) / denom for j in range(q)]\n",
    "\n",
    "        for i in range(n):\n",
    "            T[i][a] = t[i]\n",
    "        for j in range(p):\n",
    "            W[j][a] = w[j]\n",
    "            P[j][a] = p_vec[j]\n",
    "        for j in range(q):\n",
    "            Q[j][a] = q_vec[j]\n",
    "\n",
    "        for i in range(n):\n",
    "            ti = t[i]\n",
    "            for j in range(p):\n",
    "                Xh[i][j] -= ti * p_vec[j]\n",
    "            for j in range(q):\n",
    "                Yh[i][j] -= ti * q_vec[j]\n",
    "\n",
    "    return {'W': W, 'P': P, 'Q': Q, 'T': T}\n",
    "\n",
    "\n",
    "def pls_regression_coeffs(model):\n",
    "    W, P, Q = model['W'], model['P'], model['Q']\n",
    "    PT = transpose(P)\n",
    "    PTW = matmul(PT, W)\n",
    "    PTW_inv = matrix_inverse(PTW)\n",
    "    W_star = matmul(W, PTW_inv)\n",
    "    QT = transpose(Q)\n",
    "    B = matmul(W_star, QT)\n",
    "    return B\n",
    "\n",
    "\n",
    "def apply_preprocess(X, means, stds):\n",
    "    return [[(row[j] - means[j]) / stds[j] for j in range(len(row))] for row in X]\n",
    "\n",
    "\n",
    "def split_train_test_by_class(X, labels, exclude_label):\n",
    "    Xt, yt, Xe, ye = [], [], [], []\n",
    "    for row, c in zip(X, labels):\n",
    "        if c == exclude_label:\n",
    "            Xe.append(row)\n",
    "            ye.append(c)\n",
    "        else:\n",
    "            Xt.append(row)\n",
    "            yt.append(c)\n",
    "    return Xt, yt, Xe, ye\n",
    "\n",
    "\n",
    "def class_palette(classes):\n",
    "    base = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#17becf','#bcbd22','#7f7f7f']\n",
    "    return {c: base[i % len(base)] for i, c in enumerate(sorted(classes, key=lambda x: float(x)))}\n",
    "\n",
    "\n",
    "def save_scatter_svg(path, points, labels, title, xlabel, ylabel, palette, extra_text=None, highlight_label=None):\n",
    "    xs = [p[0] for p in points]\n",
    "    ys = [p[1] for p in points]\n",
    "    minx, maxx = min(xs), max(xs)\n",
    "    miny, maxy = min(ys), max(ys)\n",
    "    padx = (maxx - minx) * 0.1 or 1.0\n",
    "    pady = (maxy - miny) * 0.1 or 1.0\n",
    "    minx -= padx; maxx += padx; miny -= pady; maxy += pady\n",
    "\n",
    "    W,H = 1000,700\n",
    "    lm,rm,tm,bm = 90,220,70,80\n",
    "    pw,ph = W-lm-rm, H-tm-bm\n",
    "\n",
    "    def sx(x): return lm + (x-minx)/(maxx-minx)*pw\n",
    "    def sy(y): return tm + ph - (y-miny)/(maxy-miny)*ph\n",
    "\n",
    "    lines = [f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{W}\" height=\"{H}\">',\n",
    "             '<rect width=\"100%\" height=\"100%\" fill=\"white\"/>',\n",
    "             f'<text x=\"{W//2}\" y=\"35\" text-anchor=\"middle\" font-size=\"24\" font-family=\"Arial\">{title}</text>',\n",
    "             f'<line x1=\"{lm}\" y1=\"{tm+ph}\" x2=\"{lm+pw}\" y2=\"{tm+ph}\" stroke=\"black\"/>',\n",
    "             f'<line x1=\"{lm}\" y1=\"{tm}\" x2=\"{lm}\" y2=\"{tm+ph}\" stroke=\"black\"/>']\n",
    "\n",
    "    for i in range(6):\n",
    "        tx = minx + (maxx-minx)*i/5\n",
    "        ty = miny + (maxy-miny)*i/5\n",
    "        x = sx(tx); y = sy(ty)\n",
    "        lines.append(f'<line x1=\"{x:.1f}\" y1=\"{tm+ph}\" x2=\"{x:.1f}\" y2=\"{tm+ph+6}\" stroke=\"black\"/>')\n",
    "        lines.append(f'<text x=\"{x:.1f}\" y=\"{tm+ph+24}\" text-anchor=\"middle\" font-size=\"12\">{tx:.2f}</text>')\n",
    "        lines.append(f'<line x1=\"{lm-6}\" y1=\"{y:.1f}\" x2=\"{lm}\" y2=\"{y:.1f}\" stroke=\"black\"/>')\n",
    "        lines.append(f'<text x=\"{lm-10}\" y=\"{y+4:.1f}\" text-anchor=\"end\" font-size=\"12\">{ty:.2f}</text>')\n",
    "\n",
    "    for (x,y),lab in zip(points,labels):\n",
    "        color = palette.get(lab,'#000')\n",
    "        r = 7 if lab == highlight_label else 5\n",
    "        stroke = 'black' if lab == highlight_label else 'none'\n",
    "        lines.append(f'<circle cx=\"{sx(x):.2f}\" cy=\"{sy(y):.2f}\" r=\"{r}\" fill=\"{color}\" stroke=\"{stroke}\" opacity=\"0.82\"/>')\n",
    "\n",
    "    lines.append(f'<text x=\"{lm+pw/2:.1f}\" y=\"{H-25}\" text-anchor=\"middle\" font-size=\"16\">{xlabel}</text>')\n",
    "    lines.append(f'<text x=\"30\" y=\"{tm+ph/2:.1f}\" text-anchor=\"middle\" font-size=\"16\" transform=\"rotate(-90 30 {tm+ph/2:.1f})\">{ylabel}</text>')\n",
    "\n",
    "    legend_y = 90\n",
    "    lines.append(f'<text x=\"{W-rm+10}\" y=\"{legend_y-20}\" font-size=\"16\">Классы</text>')\n",
    "    for i,lab in enumerate(sorted(set(labels), key=lambda x: float(x))):\n",
    "        y = legend_y + i*26\n",
    "        lines.append(f'<rect x=\"{W-rm+10}\" y=\"{y-12}\" width=\"14\" height=\"14\" fill=\"{palette.get(lab,\"#000\")}\"/>')\n",
    "        lines.append(f'<text x=\"{W-rm+34}\" y=\"{y}\" font-size=\"14\">{lab}</text>')\n",
    "\n",
    "    if extra_text:\n",
    "        lines.append(f'<text x=\"{W-rm+10}\" y=\"{H-90}\" font-size=\"13\">{extra_text}</text>')\n",
    "\n",
    "    lines.append('</svg>')\n",
    "    with open(path,'w',encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(lines))\n",
    "\n",
    "\n",
    "def save_pred_plot(path, true_vals, pred_vals, labels, excluded_label):\n",
    "    points = list(zip(true_vals,pred_vals))\n",
    "    palette = class_palette(labels)\n",
    "    save_scatter_svg(\n",
    "        path,\n",
    "        points,\n",
    "        labels,\n",
    "        title=f'PLS прогноз класса (модель без класса {excluded_label})',\n",
    "        xlabel='Истинный класс (числовое значение)',\n",
    "        ylabel='Предсказание PLS',\n",
    "        palette=palette,\n",
    "        extra_text='Черная обводка: исключенный из обучения класс',\n",
    "        highlight_label=excluded_label,\n",
    "    )\n",
    "\n",
    "\n",
    "def argmax(row):\n",
    "    best_i, best_v = 0, row[0]\n",
    "    for i, v in enumerate(row[1:], 1):\n",
    "        if v > best_v:\n",
    "            best_i, best_v = i, v\n",
    "    return best_i\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    _, labels, names, Xraw = read_dataset(r'C:\\Users\\gusen\\Downloads\\аспер\\5сем\\data\\pmma_init.csv')\n",
    "\n",
    "    X = snv(Xraw)\n",
    "    Xz, x_mean, x_std = center_scale(X)\n",
    "\n",
    "    # PCA\n",
    "    pca_t, pca_var = pca_scores(Xz, n_components=2)\n",
    "    palette = class_palette(labels)\n",
    "    save_scatter_svg(\n",
    "        'outputs/pca_scores.svg',\n",
    "        pca_t,\n",
    "        labels,\n",
    "        title='PCA после SNV + autoscaling',\n",
    "        xlabel=f'PC1 ({pca_var[0]*100:.1f}% для первых 2 ПК)',\n",
    "        ylabel=f'PC2 ({pca_var[1]*100:.1f}% для первых 2 ПК)',\n",
    "        palette=palette,\n",
    "    )\n",
    "\n",
    "    # PLS (multi-class one-hot)\n",
    "    Y, class_order = one_hot(labels)\n",
    "    Yz, y_mean, y_std = center_scale(Y)\n",
    "    pls_model = pls_nipals(Xz, Yz, n_components=2)\n",
    "    T = pls_model['T']\n",
    "    save_scatter_svg(\n",
    "        'outputs/pls_scores.svg',\n",
    "        [[row[0], row[1]] for row in T],\n",
    "        labels,\n",
    "        title='PLS score plot (2 латентные переменные)',\n",
    "        xlabel='LV1',\n",
    "        ylabel='LV2',\n",
    "        palette=palette,\n",
    "    )\n",
    "\n",
    "    # PLS-DA prediction on all data\n",
    "    B = pls_regression_coeffs(pls_model)\n",
    "    Yhat_z = matmul(Xz, B)\n",
    "    Yhat = [[Yhat_z[i][j] * y_std[j] + y_mean[j] for j in range(len(y_mean))] for i in range(len(Yhat_z))]\n",
    "    pred_idx = [argmax(r) for r in Yhat]\n",
    "    true_idx = [class_order.index(c) for c in labels]\n",
    "    acc = sum(1 for a, b in zip(pred_idx, true_idx) if a == b) / len(labels)\n",
    "\n",
    "    # PLS-DA score plot (same scores, but keep separate figure and include accuracy note)\n",
    "    save_scatter_svg(\n",
    "        'outputs/pls_da_scores.svg',\n",
    "        [[row[0], row[1]] for row in T],\n",
    "        labels,\n",
    "        title='PLS-DA: score plot',\n",
    "        xlabel='LV1',\n",
    "        ylabel='LV2',\n",
    "        palette=palette,\n",
    "        extra_text=f'Точность на всем наборе: {acc*100:.1f}%'\n",
    "    )\n",
    "\n",
    "    # \"Intermediate class\" scenario: leave one class out for training and predict continuous class value\n",
    "    excluded = sorted(set(labels), key=lambda x: Counter(labels)[x])[0]  # rarest class\n",
    "    Xt, yt, Xe, ye = split_train_test_by_class(X, labels, excluded)\n",
    "    Xt_z, xm_t, xs_t = center_scale(Xt)\n",
    "\n",
    "    y_scalar_t = [[float(c)] for c in yt]\n",
    "    ys_t_mean = [sum(v[0] for v in y_scalar_t) / len(y_scalar_t)]\n",
    "    ys_t_std = [math.sqrt(sum((v[0]-ys_t_mean[0])**2 for v in y_scalar_t)/(len(y_scalar_t)-1))]\n",
    "    Yt_z = [[(v[0]-ys_t_mean[0])/(ys_t_std[0] if ys_t_std[0] else 1.0)] for v in y_scalar_t]\n",
    "\n",
    "    pls_missing = pls_nipals(Xt_z, Yt_z, n_components=2)\n",
    "    Bm = pls_regression_coeffs(pls_missing)\n",
    "\n",
    "    Xall_tz = apply_preprocess(X, xm_t, xs_t)\n",
    "    yhat_z = [row[0] for row in matmul(Xall_tz, Bm)]\n",
    "    yhat = [v * ys_t_std[0] + ys_t_mean[0] for v in yhat_z]\n",
    "    ytrue = [float(c) for c in labels]\n",
    "\n",
    "    save_pred_plot('outputs/pls_missing_class_prediction.svg', ytrue, yhat, labels, excluded)\n",
    "\n",
    "    with open('outputs/report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('Датасет: pmma_init.csv\\n')\n",
    "        f.write(f'Объектов: {len(labels)}\\n')\n",
    "        f.write(f'Классы: {dict(Counter(labels))}\\n')\n",
    "        f.write('Предобработка: SNV по спектру + autoscaling по признакам.\\n')\n",
    "        f.write(f'PCA (2 компоненты): вклад внутри первых 2 компонент = {sum(pca_var)*100:.2f}%\\n')\n",
    "        f.write(f'PLS-DA точность (resubstitution): {acc*100:.2f}%\\n')\n",
    "        f.write(f'Эксперимент с исключенным классом для PLS-регрессии: исключен класс {excluded}.\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
